# Mysql为什么有些瞬间很慢？

#### 还原实际场景

平时一条SQL查询都很快，但某一个瞬间查询非常慢，但这样的场景很难复现，它不只随机，而且持续时间很短。

#### 剖析原因

**先从Innodb更新的过程说起**

Innodb在处理更新操作时，只会写redo log和更新内存，然后就返回成功了。

![更新流程](./images/更新流程.png)

此时就会存在内存数据页和磁盘的数据不一致，这样的内存数据页称之为**脏页**。反之内存数据页中的数据和磁盘中的数据一致叫**干净页**

将内存中不同的数据同步到磁盘的过程，叫**刷脏页**，称之为**flush**。

![刷脏页流程](./images/刷脏页流程.png)

如上流程图，flush的过程就是将内存中的redo log日志的清掉（给其他写入腾出空间），并将最新的数据同步给磁盘。

**触发flush的场景**

- 当redo log被写满了之后，此时会停止所有更新，触发flush。

- 当系统内存不足时，需要新的内存数据页，此时要淘汰一些数据页（有淘汰策略），腾出来的内存供别的数据页使用，如果淘汰的是脏页，此时就要出发flush。

- 当系统空闲时，Mysql会见缝插针地刷一点脏页。

- 当Mysql正常关闭时，会将内存中的脏页全部写入磁盘。

**分析flush对性能的影响**

第三和第四种场景，不会有什么性能问题。

第一种：redo log写满了，要刷脏页。这种情况是不能被业务接受的，因为所有的更新操作都要停摆，从监控来看：更新数跌为0。

第二种：内存不够用，需要先将脏页写到磁盘；这种场景是**常态**。

内存数据页的三种状态：

- 未被使用；

- 使用了并是干净页；

- 使用了并是脏页；

当要读入数据页不在内存中，就必须向缓冲池申请一个数据页，这时候就需要淘汰一些数据页（淘汰哪些数据页由淘汰策略决定）。如果淘汰的是干净页，则直接释放就好（因为内存和磁盘是一样的，不需要同步磁盘）；如果淘汰的是脏页，则需要先将脏页数据写入磁盘，变成干净页才能释放。

所以两种情况刷脏页会明显影响性能：

1、一个查询要淘汰的脏页太多，导致刷脏页的时间变长；

2、redo log写满，会导致更新停摆；

#### 刷脏页的策略

知道了刷脏页有可能会影响效率，所以控制刷脏页的策略能有效避免这些情况。

**让Innodb全力刷脏页**

Mysql通过`innodb_io_capacity`参数来告诉Innodb系统的磁盘能力，对于专用的数据库服务器建议设置为磁盘的IOPS。下面命令是测试磁盘的IOPS：

```shell
 fio -filename=$filename -direct=1 -iodepth 1 -thread -rw=randrw -ioengine=psync -bs=16k -size=500M -numjobs=10 -runtime=10 -group_reporting -name=mytest 
```

实际场景中，因为设置这个参数较小，会出现这种现象：系统没有任何瓶颈，但Mysql却很慢，就是因为设置这个参数较小，Innodb认为系统的磁盘IO能力这么差，就会将刷脏页的速度变小，因此导致Mysql查询更新效率降低。

**控制刷脏页的速率**

如果不使用了专用的数据库服务器，要兼顾其他服务对磁盘的消耗，所以应该制定一个策略：

Innodb刷脏页速度要考虑两个因素：一是脏页比例；二是redo log的写入速度。

两个因素分别可以算出一个百分比R，Innodb刷脏页的速率就按照`innodb_io_capacity`的R%来刷脏页。

要避免这种情况，要合理设置`innodb_io_capacity`的值，并且要多关注脏页比例，不要让他经常接近75%。以下是计算脏页比例的方法：

```sql
select VARIABLE_VALUE into @a from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_dirty';
select VARIABLE_VALUE into @b from global_status where VARIABLE_NAME = 'Innodb_buffer_pool_pages_total';
select @a/@b;
```

#### 刷脏页的其他情况

一旦一个查询需要刷脏页时，就会比平时查询要慢。另外Mysql有另一种机制，如果刷的脏页的旁边的数据页也是脏页，也会“连坐”一起刷掉，依次循环，这样会更慢。这个机制通过`innodb_flush_neighbors`参数来控制，为0不需要“连坐”，为1需要“连坐”。

如果使用专用的数据库服务器，一般都将`innodb_flush_neighbors`设置为0。另外在mysql8.0之后已经将`innodb_flush_neighbors`默认为0了。

# 为什么Delete表记录，表文件却没有变小？

在日常业务中，我们删除了表中的一大半记录，但表文件大小却没有变化，这是什么原因呢？

#### 讨论原因

从delete流程说起：

![Delete流程](./images/Delete流程.png)

上图是Innodb索引数据页存储，当delete 400这条记录时，并不会将400这个位置删除，而是标记为可复用。当以后插入数据为300-700的数据时，可以继续复用400这个位置。如果这个数据页都被删除，那么整个数据页都可以被复用而且不受ID的限制。

这就是为什么delete删除记录，表文件大小为什么没有变化的原因。

其实除了delete会造成空洞，随机插入数据也造成空洞，因为随机插入会造成页分裂，导致中间的空洞。

#### 如何回收表空间

对于出现大量空洞的表，只能通过重建表来回收表空间。

重建表的逻辑是新建一个临时表B，将表A的数据取出来依次插入临时表B，这样就紧凑的不会有数据空洞。

重建表：（Mysql5.5版本及之前版本）

```sql
alter table A engine=InnoDB;
-- copy的形式，生成一个临时表进行copy
alter table t engine=innodb,ALGORITHM=copy;
```

上面的DDL语句需要在执行过程中需要获取MDL写锁，会阻塞新的更新操作，因此这种方法不是Online。

Online重建表：（Mysql5.6开始才支持）

```sql
alter table A engine=InnoDB;
-- inplace形式，在Innodb内部重建
alter table t engine=innodb,ALGORITHM=inplace;
```

Online DDL的流程：

1、建立一个临时文件，扫描表A的所有数据页；

2、用数据页中表A的记录生成B+Tree树存放到临时文件；

3、在生成临时文件的过程中，如果有新的更新语句写到一个日志文件中（row log）；

4、临时文件生成之后，将变更的row log运用到临时文件；

5、用临时文件替换表A的数据文件；

Online DDL因为记录了变更的日志文件（row log），所以此时的MDL写锁退化成读锁，这样就不用阻塞增删改查。那为什么不直接解锁（读锁都不要），是因为防止其他DDL语句。

虽然说Online DDL是Online的，但对于很大的表来说，这个操作是很消耗IO和CPU资源，所以Online DDL不要在线上执行大表的重建。

# count的问题

在日常开发中，我们经常会遇到统计大表总数的场景，但随着表越来越大，`count(*)`会越来越慢了。

#### count(*)的实现方式

不同的存储引擎实现方式不一样：

- MyISAM引擎是将一个表的总行数记录下来并存储到磁盘中的，`count(*)`的时候直接返回这个值就好了，效率很高；但要注意的是带where条件就慢了，也需要扫描行数累加。

- Innodb引擎是将数据一行一行的从引擎中读出来，然后累计计数，效率很低；

#### 为什么Innodb引擎不存储一个总数

因为Innodb要支持MVCC多版本并发控制，在不同的session中需要返回自己可见的行数，所以Innodb不能记录一个总数。

比如下面的场景：

![Innodb的count场景](./images/Innodb下的count.jpg)

- session A先启动一个事务，在RR下，始终读取到的都是1000；

- session B在session C后启动一个事务，开启事务时是1001，然后又insert了一条数据，所以统计到的数据是1002；

- session C统计数量时已经session C已经insert一条记录，但session B事务还没提交，所以session C统计的数量是1001；

#### 大表count(*)如何优化

**1.不带where条件的count**

可以通过计数的方式来解决，当新增一条记录时+1，当删除一条记录时-1。

首先想到的是通过redis来计数，当新增一条记录时+1，当删除一条记录时-1，如果缓存丢失了，可以再次进行count进行设置，但是会存在redis中的计数和实际查询出来的记录不一致的问题：

![redis计数问题](./images/redis计数问题.jpg)

如上图的场景，当插入数据库和redis累加的中间时刻存在读取数据，就会导致redis中的总数和实际数据库中的数据不一致的问题。

再想到是通过数据库来计数，按照redis的思路依然是存在前后不一致的问题，但是可以通过事务的方式来解决：

![统计表统计](./images/统计表统计count.jpg)

如上图场景，session B在查询时开启事务，session A还没有提交时，session B是不会读到对应的变更，用这样来保持一致，但这种方案会影响性能。

**2.带where条件的count**

尽量where条件使用索引。

#### 讨论一下不同count的效率

日常开发中，我们常见的count有这几种：`count(*)`、`count(1)`、`count(字段)`、`count(主键)`。

这几种不同的count方式有什么不同？

- `count(主键)`：InnoDB 引擎会遍历整张表，把每一行的 id 值都取出来，返回给 server 层。server 层拿到 id 后，判断是不可能为空的，就按行累加。

- `count(1)`：InnoDB 引擎遍历整张表，但不取值。server 层对于返回的每一行，放一个数字“1”进去，判断是不可能为空的，按行累加。单看这两个用法的差别的话`count(1)` 执行得要比`count(主键 )` 快。因为从引擎返回 id 会涉及到解析数据行，以及拷贝字段值的操作。

- `count(字段)`：分两种情况：
  
  - 如果这个“字段”是定义为 not null 的话，一行行地从记录里面读出这个字段，判断不能为 null，按行累加；
  
  - 如果这个“字段”定义允许为 null，那么执行的时候，判断到有可能是 null，还要把值取出来再判断一下，不是 null 才累加。

- `count(*)`：并不会把全部字段取出来，而是专门做了优化，不取值。count(*) 肯定不是 null，按行累加。

所以效率对比：`count(字段)` < `count(主键)` < `count(1)` = `count(*)`
