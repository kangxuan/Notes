# RAG

### 概念

`Retrieval Augmented Generation`，检索增强生成，是一种结合信息检索和文本生成的技术。RAG通过实时检索相关文档或信息，并将其作为上下文输入到生成模型中，从而提高生成结果的时效性和准确性。

![rag流程图](./images/rag流程.png)

### RAG的核心用途

**1、解决知识时效性问题**

LLM的训练数据通常是静态的，无法涵盖最新的信息，而RAG可以检索外部知识库实时更新信息。

**2、解决幻觉问题**

通过引入外部知识库，RAG能够减少模型生成虚假或不准确的胡编乱造。

**3、提升专业领域回答质量**

RAG能够结合垂直领域的专业知识库，生成更专业更有深度的回答。

### RAG的核心原理和流程

这里说的是NativeRAG，即推理中使用RAG。

##### 1、数据预处理

- **知识库构建：** 收集并整理文档、网页、数据库等多源数据，构建知识库，一般由数据治理团队去做。

- **文档分块：** 将文档切分为合适大小的块（chunk），以便后续检索。分块策略需要在语义完整性与检索效率之间取得平衡。

- **向量化存储：** 使用嵌入模型（如BGE、M3E等Embedding模型）将chunk转换为统一维度的向量，并存储到向量数据库中

##### 2、检索阶段

- **查询处理：** 将用户的问题（query）转换成向量，并在向量数据库中进行相似度检索，并返回最相似的（最相关的）chunk。

- **重排序：** 对检索返回的数据进行相关性排序，选择最相关的片段作为生成阶段的输入和上下文。

##### 3、生成阶段

- **上下文组装：** 将用户的问题（query）和检索到的chunk结合，形成增强的上下文输入。

- **生成回答：** LLM基于增强的上下文生成最终回答。

![RAG步骤](./images/rag步骤.png)

### chunk切分策略

切片是RAG的核心环节，直接影响到检索质量和回答准确性。

##### 1、改进版固定长度切片

在固定长度切片的基础上，优先在句子边界进行切分，通过重叠机制确保上下文连续性，同时保持长度可控。

**特点：** 实现简单，处理速度快，长度统一，合适规范文件。

**合适场景：** 需要统一处理长度的场景，批量处理大量文档。

```python
def improved_fixed_length_chunking(text, chunk_size=512, overlap=50):
    chunks = []
    start = 0
    # 遍历这个文本
    while start < len(text):
        # 初步计算切片结束位置：起始位置 + 目标切片大小
        end = start + chunk_size

        # 尝试在句子边界切分
        if end < len(text):
            # 寻找最近的句子结束符
            # 从最后一个下标往前找到第一个出现.!?。！？，并切断
            for i in range(end, max(start, end - 100), -1):
                if text[i] in '.!?。！？':
                    end = i + 1
                    break

        chunk = text[start:end]

        # 去除首尾空格后检查长度，确保非空切片才加入列表
        if len(chunk.strip()) > 0:
            chunks.append(chunk.strip())

        # 确保相邻切片有 overlap 个字符的重叠，避免信息丢失
        start = end - overlap

    return chunks
```

##### 2、语义切片

基于自然语言处理，按照句子、段落等语义单位进行切分。保持语义完整性，避免在句子中断开，确保每个切片都是完整的语义单元，且无重叠。

**特点：** 语义保持好，检索准确性高，但长度可能不均匀。

**合适场景：** 合适自然语言文本，需要保持完整语义的场景。

```python
def semantic_chunking(text, max_chunk_size=512):
    """基于语义的切片 - 按句子分割
    """
    # 使用正则表达式分割文本成句子数组
    sentences = re.split(r'[.!?。！？\n]+', text)
    chunks = []
    current_chunk = ""

    # 遍历句子数组
    for sentence in sentences:
        # 如果句子是空则不用跳过处理
        sentence = sentence.strip()
        if not sentence:
            continue
        # 如果当前句子加入后超过chunk最大长度，保存当前块到chunks，否则追加到到当前快
        if len(current_chunk) + len(sentence) > max_chunk_size and current_chunk:
            chunks.append(current_chunk.strip())
            current_chunk = sentence
        else:
            current_chunk += " " + sentence if current_chunk else sentence

    # 添加最后一块
    if current_chunk.strip():
        chunks.append(current_chunk.strip())

    return chunks
```

##### 3、LLM语义切片

利用LLM的语义理解能力，在保持语义完整性的同时实现精确的长度控制。

**特点：** 语义理解能力强，分割点智能选择，但依赖LLM，成本较高。

**合适场景：** 高质量要求的场景，复杂语义结构，有预算支持的项目。

```python
def advanced_semantic_chunking_with_llm(text, max_chunk_size=300):
    """ 使用LLM进行高级语义切片 """
    # 检查是否设置了API密钥
    api_key = "xxxxxxxxxxxxxxxxxxxxxxxxxxx"
    if not api_key:
        print("警告: 未设置 DASHSCOPE_API_KEY 环境变量，将使用基础语义切片")
        return fallback_semantic_chunking(text, max_chunk_size)

    client = OpenAI(
        api_key=api_key,
        base_url="https://dashscope.aliyuncs.com/compatible-mode/v1",
    )

    prompt = f"""
请将以下文本按照语义完整性进行切片，每个切片不超过{max_chunk_size}字符。
要求：
1. 保持语义完整性
2. 在自然的分割点切分
3. 返回JSON格式的切片列表，格式如下：
{{
  "chunks": [
    "第一个切片内容",
    "第二个切片内容",
    ...
  ]
}}

文本内容：
{text}

请返回JSON格式的切片列表：
"""

    try:
        print("正在调用LLM进行语义切片...")
        response = client.chat.completions.create(
            model="qwen-turbo-latest",
            messages=[
                {"role": "system", "content": "你是一个专业的文本切片助手。请严格按照JSON格式返回结果，不要添加任何额外的标记。"},
                {"role": "user", "content": prompt}
            ]
        )
        result = response.choices[0].message.content
        print(f"LLM返回结果: {result[:200]}...")

        # 清理结果，移除可能的Markdown代码块标记
        cleaned_result = result.strip()
        if cleaned_result.startswith('```'):
            # 移除开头的 ```json 或 ```
            cleaned_result = re.sub(r'^```(?:json)?\s*', '', cleaned_result)
        if cleaned_result.endswith('```'):
            # 移除结尾的 ```
            cleaned_result = re.sub(r'\s*```$', '', cleaned_result)

        # 解析JSON结果
        chunks_data = json.loads(cleaned_result)
        # 处理不同的返回格式
        if "chunks" in chunks_data:
            return chunks_data["chunks"]
        elif "slice" in chunks_data:
            # 如果返回的是包含"slice"字段的列表
            if isinstance(chunks_data, list):
                return [item.get("slice", "") for item in chunks_data if item.get("slice")]
            else:
                return [chunks_data["slice"]]
        else:
            # 如果直接返回字符串列表
            if isinstance(chunks_data, list):
                return chunks_data
            else:
                print(f"意外的返回格式: {chunks_data}")
                return []

    except json.JSONDecodeError as e:
        print(f"JSON解析失败: {e}")
        print(f"原始结果: {result}")
        # 尝试手动解析
        try:
            # 尝试提取JSON部分
            json_match = re.search(r'\{.*\}', result, re.DOTALL)
            if json_match:
                json_str = json_match.group()
                chunks_data = json.loads(json_str)
                if "chunks" in chunks_data:
                    return chunks_data["chunks"]
        except:
            pass

    except Exception as e:
        print(f"LLM切片失败: {e}")
        return fallback_semantic_chunking(text, max_chunk_size)
```

##### 4、层次切片

如果文档是具有层次结构的，比如markdown文档就具有层次结构，可以按照层级进行切片：

```python
# 测试文本 - 包含层次结构
text = """
# 迪士尼乐园门票指南

## 一、门票类型介绍

### 1. 基础门票类型
迪士尼乐园提供多种门票类型以满足不同游客需求。一日票是最基础的门票类型，可在购买时选定日期使用，价格根据季节浮动。两日票需要连续两天使用，总价比购买两天单日票优惠约9折。特定日票包含部分节庆活动时段，需注意门票标注的有效期限。

### 2. 特殊门票类型
年票适合经常游玩的游客，提供更多优惠和特权。VIP门票包含快速通道服务，可减少排队时间。团体票适用于10人以上团队，享受团体折扣。

## 二、购票渠道与流程

### 1. 官方购票渠道
购票渠道以官方渠道为主，包括上海迪士尼官网、官方App、微信公众号及小程序。这些渠道提供最可靠的服务和最新的票务信息。

### 2. 第三方平台
第三方平台如飞猪、携程等合作代理商也可购票，但需认准官方授权标识。建议优先选择官方渠道以确保购票安全。

### 3. 证件要求
所有电子票需绑定身份证件，港澳台居民可用通行证，外籍游客用护照，儿童票需提供出生证明或户口本复印件。

## 三、入园须知

### 1. 入园时间
乐园通常在上午8:00开园，晚上8:00闭园，具体时间可能因季节和特殊活动调整。建议提前30分钟到达园区。

### 2. 安全检查
入园前需要进行安全检查，禁止携带危险物品、玻璃制品等。建议轻装简行，提高入园效率。

### 3. 园区服务
园区内提供寄存服务、轮椅租赁、婴儿车租赁等服务，可在游客服务中心咨询详情。

生日福利需在官方渠道登记，可获赠生日徽章和甜品券。半年内有效结婚证持有者可购买特别套票，含皇家宴会厅双人餐。军人优惠现役及退役军人凭证件享8折，需至少提前3天登记审批。
"""

def hierarchical_slice(text, target_size=300, preserve_hierarchy=True):
    """
    层次切片函数，根据段落和标题结构进行切片，确保每个切片的字符数不超过目标值。

    :param text: 待切片的文本字符串
    :param target_size: 每个切片的目标字符数，默认300
    :param preserve_hierarchy: 是否保留段落和标题结构，默认True
    :return: 切片后的文本列表
    """
    chunks = []

    # 定义层次标记
    hierarchy_markers = {
        'title1': ['# ', '标题1：', '一、', '1. '],
        'title2': ['## ', '标题2：', '二、', '2. '],
        'title3': ['### ', '标题3：', '三、', '3. '],
        'paragraph': ['\n\n', '\n']
    }

    # 分割文本为行
    lines = text.split('\n')
    current_chunk = ""
    current_hierarchy = []

    for line in lines:
        line = line.strip()
        if not line:
            continue

        # 检测当前行是否为层级级别
        line_level = None
        for level, markers in hierarchy_markers.items():
            for marker in markers:
                if line.startswith(marker):
                    line_level = level
                    break
            if line_level:
                break

        # 如果没有检测到层次标记，默认为段落
        if not line_level:
            line_level = 'paragraph'

        # 判断是否需要开始新的切片
        should_start_new_chunk = False

        # 1. 如果遇到更高级别的标题，开始新切片
        if preserve_hierarchy and line_level in ['title1', 'title2']:
            should_start_new_chunk = True

        # 2. 如果当前切片长度超过目标大小
        if len(current_chunk) + len(line) > target_size and current_chunk.strip():
            should_start_new_chunk = True

        # 3. 如果遇到段落分隔符且当前切片已经足够长
        if line_level == 'paragraph' and len(current_chunk) > target_size * 0.8:
            should_start_new_chunk = True

        # 开始新切片
        if should_start_new_chunk and current_chunk.strip():
            chunks.append(current_chunk.strip())
            current_chunk = ""
            current_hierarchy = []

        # 添加当前行到切片
        if current_chunk:
            current_chunk += "\n" + line
        else:
            current_chunk = line

        # 更新层次信息
        if line_level != 'paragraph':
            current_hierarchy.append(line_level)

    # 处理最后一个切片
    if current_chunk.strip():
        chunks.append(current_chunk.strip())

    return chunks

def print_chunk_analysis(chunks, method_name):
    """打印切片分析结果"""
    print(f"\n{'='*60}")
    print(f"📋 {method_name}")
    print(f"{'='*60}")

    if not chunks:
        print("❌ 未生成任何切片")
        return

    total_length = sum(len(chunk) for chunk in chunks)
    avg_length = total_length / len(chunks)
    min_length = min(len(chunk) for chunk in chunks)
    max_length = max(len(chunk) for chunk in chunks)

    print(f"📊 统计信息:")
    print(f"   - 切片数量: {len(chunks)}")
    print(f"   - 平均长度: {avg_length:.1f} 字符")
    print(f"   - 最短长度: {min_length} 字符")
    print(f"   - 最长长度: {max_length} 字符")
    print(f"   - 长度方差: {max_length - min_length} 字符")

    print(f"\n📝 切片内容:")
    for i, chunk in enumerate(chunks, 1):
        print(f"   块 {i} ({len(chunk)} 字符):")
        print(f"   {chunk}")
        print()

if __name__ == '__main__':
    print("层次切片策略测试")
    print(f"测试文本长度: {len(text)} 字符")

    # 使用层次切片
    slices = hierarchical_slice(text, target_size=300, preserve_hierarchy=True)
    print(f"生成的切片数量: {len(slices)}")
    for i, slice in enumerate(slices, 1):
        print(f"切片 {i}: {slice[:300]}...")  # 仅显示前300个字符
```

执行结果：

```shell
层次切片策略测试
测试文本长度: 725 字符
生成的切片数量: 4
切片 1: # 迪士尼乐园门票指南...
切片 2: ## 一、门票类型介绍
### 1. 基础门票类型
迪士尼乐园提供多种门票类型以满足不同游客需求。一日票是最基础的门票类型，可在购买时选定日期使用，价格根据季节浮动。两日票需要连续两天使用，总价比购买两天单日票优惠约9折。特定日票包含部分节庆活动时段，需注意门票标注的有效期限。
### 2. 特殊门票类型
年票适合经常游玩的游客，提供更多优惠和特权。VIP门票包含快速通道服务，可减少排队时间。团体票适用于10人以上团队，享受团体折扣。...
切片 3: ## 二、购票渠道与流程
### 1. 官方购票渠道
购票渠道以官方渠道为主，包括上海迪士尼官网、官方App、微信公众号及小程序。这些渠道提供最可靠的服务和最新的票务信息。
### 2. 第三方平台
第三方平台如飞猪、携程等合作代理商也可购票，但需认准官方授权标识。建议优先选择官方渠道以确保购票安全。
### 3. 证件要求
所有电子票需绑定身份证件，港澳台居民可用通行证，外籍游客用护照，儿童票需提供出生证明或户口本复印件。...
切片 4: ## 三、入园须知
### 1. 入园时间
乐园通常在上午8:00开园，晚上8:00闭园，具体时间可能因季节和特殊活动调整。建议提前30分钟到达园区。
### 2. 安全检查
入园前需要进行安全检查，禁止携带危险物品、玻璃制品等。建议轻装简行，提高入园效率。
### 3. 园区服务
园区内提供寄存服务、轮椅租赁、婴儿车租赁等服务，可在游客服务中心咨询详情。
生日福利需在官方渠道登记，可获赠生日徽章和甜品券。半年内有效结婚证持有者可购买特别套票，含皇家宴会厅双人餐。军人优惠现役及退役军人凭证件享8折，需至少提前3天登记审批。...
```

##### 5、滑动窗口切片

滑动窗口是通过一定步长向后获取固定长度的chunk，包含了部分重叠来保证完整语义不被切分。

```python
# 测试文本
text = """
迪士尼乐园提供多种门票类型以满足不同游客需求。一日票是最基础的门票类型，可在购买时选定日期使用，价格根据季节浮动。两日票需要连续两天使用，总价比购买两天单日票优惠约9折。特定日票包含部分节庆活动时段，需注意门票标注的有效期限。

购票渠道以官方渠道为主，包括上海迪士尼官网、官方App、微信公众号及小程序。第三方平台如飞猪、携程等合作代理商也可购票，但需认准官方授权标识。所有电子票需绑定身份证件，港澳台居民可用通行证，外籍游客用护照，儿童票需提供出生证明或户口本复印件。

生日福利需在官方渠道登记，可获赠生日徽章和甜品券。半年内有效结婚证持有者可购买特别套票，含皇家宴会厅双人餐。军人优惠现役及退役军人凭证件享8折，需至少提前3天登记审批。
"""

def sliding_window_chunking(text, window_size=512, step_size=256):
    """滑动窗口切片"""
    chunks = []

    for i in range(0, len(text), step_size):
        chunk = text[i:i + window_size]

        if len(chunk.strip()) > 0:
            chunks.append(chunk.strip())

    return chunks

def print_chunk_analysis(chunks, method_name):
    """打印切片分析结果"""
    print(f"\n{'='*60}")
    print(f"📋 {method_name}")
    print(f"{'='*60}")

    if not chunks:
        print("❌ 未生成任何切片")
        return

    total_length = sum(len(chunk) for chunk in chunks)
    avg_length = total_length / len(chunks)
    min_length = min(len(chunk) for chunk in chunks)
    max_length = max(len(chunk) for chunk in chunks)

    print(f"📊 统计信息:")
    print(f"   - 切片数量: {len(chunks)}")
    print(f"   - 平均长度: {avg_length:.1f} 字符")
    print(f"   - 最短长度: {min_length} 字符")
    print(f"   - 最长长度: {max_length} 字符")
    print(f"   - 长度方差: {max_length - min_length} 字符")

    print(f"\n📝 切片内容:")
    for i, chunk in enumerate(chunks, 1):
        print(f"   块 {i} ({len(chunk)} 字符):")
        print(f"   {chunk}")
        print()

if __name__ == '__main__':
    print("🎯 滑动窗口切片策略测试")
    print(f"📄 测试文本长度: {len(text)} 字符")

    # 使用滑动窗口切片
    chunks = sliding_window_chunking(text, window_size=300, step_size=150)
    print_chunk_analysis(chunks, "滑动窗口切片") 
```

运行结果：

```shell
# 测试文本
text = """
迪士尼乐园提供多种门票类型以满足不同游客需求。一日票是最基础的门票类型，可在购买时选定日期使用，价格根据季节浮动。两日票需要连续两天使用，总价比购买两天单日票优惠约9折。特定日票包含部分节庆活动时段，需注意门票标注的有效期限。

购票渠道以官方渠道为主，包括上海迪士尼官网、官方App、微信公众号及小程序。第三方平台如飞猪、携程等合作代理商也可购票，但需认准官方授权标识。所有电子票需绑定身份证件，港澳台居民可用通行证，外籍游客用护照，儿童票需提供出生证明或户口本复印件。

生日福利需在官方渠道登记，可获赠生日徽章和甜品券。半年内有效结婚证持有者可购买特别套票，含皇家宴会厅双人餐。军人优惠现役及退役军人凭证件享8折，需至少提前3天登记审批。
"""

def sliding_window_chunking(text, window_size=512, step_size=256):
    """滑动窗口切片"""
    chunks = []

    for i in range(0, len(text), step_size):
        chunk = text[i:i + window_size]

        if len(chunk.strip()) > 0:
            chunks.append(chunk.strip())

    return chunks

def print_chunk_analysis(chunks, method_name):
    """打印切片分析结果"""
    print(f"\n{'='*60}")
    print(f"📋 {method_name}")
    print(f"{'='*60}")

    if not chunks:
        print("❌ 未生成任何切片")
        return

    total_length = sum(len(chunk) for chunk in chunks)
    avg_length = total_length / len(chunks)
    min_length = min(len(chunk) for chunk in chunks)
    max_length = max(len(chunk) for chunk in chunks)

    print(f"📊 统计信息:")
    print(f"   - 切片数量: {len(chunks)}")
    print(f"   - 平均长度: {avg_length:.1f} 字符")
    print(f"   - 最短长度: {min_length} 字符")
    print(f"   - 最长长度: {max_length} 字符")
    print(f"   - 长度方差: {max_length - min_length} 字符")

    print(f"\n📝 切片内容:")
    for i, chunk in enumerate(chunks, 1):
        print(f"   块 {i} ({len(chunk)} 字符):")
        print(f"   {chunk}")
        print()

if __name__ == '__main__':
    print("🎯 滑动窗口切片策略测试")
    print(f"📄 测试文本长度: {len(text)} 字符")

    # 使用滑动窗口切片
    chunks = sliding_window_chunking(text, window_size=300, step_size=150)
    print_chunk_analysis(chunks, "滑动窗口切片") 
```

运行结果：

```shell
🎯 滑动窗口切片策略测试
📄 测试文本长度: 324 字符

============================================================
📋 滑动窗口切片
============================================================
📊 统计信息:
   - 切片数量: 3
   - 平均长度: 165.0 字符
   - 最短长度: 23 字符
   - 最长长度: 299 字符
   - 长度方差: 276 字符

📝 切片内容:
   块 1 (299 字符):
   迪士尼乐园提供多种门票类型以满足不同游客需求。一日票是最基础的门票类型，可在购买时选定日期使用，价格根据季节浮动。两日票需要连续两天使用，总价比购买两天单日票优惠约9折。特定日票包含部分节庆活动时段，需注意门票标注的有效期限。

购票渠道以官方渠道为主，包括上海迪士尼官网、官方App、微信公众号及小程序。第三方平台如飞猪、携程等合作代理商也可购票，但需认准官方授权标识。所有电子票需绑定身份证件，港澳台居民可用通行证，外籍游客用护照，儿童票需提供出生证明或户口本复印件。

生日福利需在官方渠道登记，可获赠生日徽章和甜品券。半年内有效结婚证持有者可购买特别套票，含皇家宴会厅双人餐。军人优惠现役及

   块 2 (173 字符):
   小程序。第三方平台如飞猪、携程等合作代理商也可购票，但需认准官方授权标识。所有电子票需绑定身份证件，港澳台居民可用通行证，外籍游客用护照，儿童票需提供出生证明或户口本复印件。

生日福利需在官方渠道登记，可获赠生日徽章和甜品券。半年内有效结婚证持有者可购买特别套票，含皇家宴会厅双人餐。军人优惠现役及退役军人凭证件享8折，需至少提前3天登记审批。

   块 3 (23 字符):
   退役军人凭证件享8折，需至少提前3天登记审批。
```

### Embedding模型的分类和选择

Embedding模型排名在huggingface网站中实时更新，可根据实际情况选择：[Embedding排名网站]([MTEB Leaderboard - a Hugging Face Space by mteb](https://huggingface.co/spaces/mteb/leaderboard))

##### 1、通用文本嵌入模型

- **BGE-M3**（智源研究院）：支持100+语言，融合密集、稀疏、多向量混合检索，适合跨语言长文档检索。适合跨语言长文档检索、高精度RAG应用。

- **text-embedding-3-large**（OpenAI）：向量维度3072，长文本语义捕捉能力强，英文表现优秀。英文内容优先的全球化应用。

##### 2、中文嵌入模型

##### 3、指令驱动和复杂任务模型

##### 4、企业级与复杂系统

### CASE1：BGE-M3使用

针对于BGE-M3模型的使用，需要运行在GPU上，可以在AutoDL上租用GPU服务器试用，modescope也提供了免费的GPU可以使用。

##### 1、先下载必要的包

```shell
pip install modelscope
pip install -U FlagEmbedding
```

##### 2、下载bge-m3模型

```python
#通过modelscope下载BGE-M3模型
from modelscope import snapshot_download
model_dir = snapshot_download('BAAI/bge-m3', cache_dir='/root/autodl-tmp/models')
print(model_dir)
```

运行结果：

```shell
/root/autodl-tmp/models/BAAI/bge-m3
```

##### 3、使用bge-m3计算相似度

```python
from FlagEmbedding import BGEM3FlagModel

# 声明Embedding模型
model = BGEM3FlagModel('/root/autodl-tmp/models/BAAI/bge-m3',  
                       use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation
#
sentences_1 = ["What is BGE M3?", "Defination of BM25"]
sentences_2 = ["BGE M3 is an embedding model supporting dense retrieval, lexical matching and multi-vector interaction.", 
               "BM25 is a bag-of-words retrieval function that ranks a set of documents based on the query terms appearing in each document"]

# 将文本转换为向量
embeddings_1 = model.encode(sentences_1, 
                            batch_size=12, 
                            max_length=8192, # If you don't need such a long length, you can set a smaller value to speed up the encoding process.
                            )['dense_vecs']
# 将文本转化为向量
embeddings_2 = model.encode(sentences_2)['dense_vecs']
# 计算两组Embedding的相似度矩阵，@ 符号在Python中表示矩阵乘法运算
similarity = embeddings_1 @ embeddings_2.T
print(similarity)
```

运行结果：

```shell
[[0.6259036 0.3474958]
 [0.3498678 0.6782462]]
```

从输入结果可以看出sentences_1中的第一个元素和sentences_2中的第一个元素更相似，sentences_1中的第二个元素和sentences_2中的第二个元素更相似。

### CASE2：gte-qwen2使用

此例子在modelscope提供的免费GPU服务器上运行

##### 1、下载必要的包

```shell
pip install modelscope
pip install -U FlagEmbedding
```

##### 2、下载gte-qwen2模型

get-qwen2-7B模型太大，这里测试使用1.5B

```python
#SDK模型下载
from modelscope import snapshot_download
model_dir = snapshot_download('iic/gte_Qwen2-1.5B-instruct', cache_dir='/mnt/workspace/.cache/modelscope/models')
print(model_dir)
```

运行结果：

```shell
/mnt/workspace/.cache/modelscope/models/iic/gte_Qwen2-1___5B-instruct
```

**3、使用gte-qwen2计算相似度**

```python
from sentence_transformers import SentenceTransformer

model_dir = "/root/autodl-tmp/models/iic/gte_Qwen2-1___5B-instruct"
model = SentenceTransformer(model_dir, trust_remote_code=True)
# 设置向量维度
model.max_seq_length = 8192

queries = [
    "how much protein should a female eat",
    "summit define",
]
documents = [
    "As a general guideline, the CDC's average requirement of protein for women ages 19 to 70 is 46 grams per day. But, as you can see from this chart, you'll need to increase that if you're expecting or training for a marathon. Check out the chart below to see how much protein you should be eating each day.",
    "Definition of summit for English Language Learners. : 1  the highest point of a mountain : the top of a mountain. : 2  the highest level. : 3  a meeting or series of meetings between the leaders of two or more governments.",
]

# 将文本转化为向量
query_embeddings = model.encode(queries, prompt_name="query")
document_embeddings = model.encode(documents)

# 计算相似度矩阵
scores = (query_embeddings @ document_embeddings.T) * 100
print(scores.tolist())
```

运行结果：

```shell
[[70.00668334960938, 8.184843063354492], [14.62419319152832, 77.71407318115234]]
```

和BGE-M3效果差不多，总体是可以看出谁和谁更相似。

### CASE3：Deepseek+Faiss搭建本地知识库检索

提供了一份名为`浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf`的文件，要求通过搭建本地知识库，结合LLM实现内部知识点问答。

##### 1、PDF文本提取与处理

使用`PyPDF2`库的`PdfReader`从PDF文件中提取文本，在提取过程中记录每行文本对应的页码，便于后续溯源使用`RecursiveCharacterTextSplitter`将长文本分割成小块，便于向量化处理。

**1.1、安装PyPDF2：**

```shell
pip install PyPDF2
```

**1.2、提取PDF文本和页码信息：**

```python
from PyPDF2 import PdfReader
from typing import List, Tuple
def extract_text_with_page_numbers(pdf) -> Tuple[str, List[Tuple[str, int]]]:
    """
    从PDF中提取文本并记录每个字符对应的页码

    参数:
        pdf: PDF文件对象

    返回:
        text: 提取的文本内容
        char_page_mapping: 每个字符对应的页码列表
    """
    text = ""
    char_page_mapping = []

    for page_number, page in enumerate(pdf.pages, start=1):
        extracted_text = page.extract_text()
        if extracted_text:
            text += extracted_text
            # 为当前页面的每个字符记录页码
            char_page_mapping.extend([page_number] * len(extracted_text))
        else:
            print(f"No text found on page {page_number}.")

    return text, char_page_mapping
# 读取PDF文件
pdf_reader = PdfReader('./浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf')
# 提取文本和页码信息
text, char_page_mapping = extract_text_with_page_numbers(pdf_reader)
print('text=',text,'char_page_mapping=',char_page_mapping)
```

执行结果：

```shell
text= 百度文库  - 好好学习，天天向上  
-1 上海浦东发展银行西安分行  
个金客户经理管理考核暂行办法  


第一章  总   则 
第一条   为保证我分行个金客户经理制的顺利实施，有效调动个
金客户经理的积极性，促进个金业务快速、稳定地发展，根据总行《上
海浦东发展银行个人金融营销体系建设方案（试行）》要求，特制定
《上海浦东发展银行西安分行个金客户经理管理考核暂行办法（试
行）》（以下简称本办法）。  
第二条   个金客户经理系指各支行（营业部）从事个人金融产品
营销与市场开拓，为我行个人客户提供综合银行服务的我行市场人
员。 
第三条   考核内容分为二大类， 即个人业绩考核、 工作质量考核。
个人业绩包括个人资产业务、负债业务、卡业务。工作质量指个人业
务的资产质量。  
第四条   为规范激励规则，客户经理的技术职务和薪资实行每年
考核浮动。客户经理的奖金实行每季度考核浮动，即客户经理按其考
核内容得分与行员等级结合，享受对应的行员等级待遇。  
 百度文库  - 好好学习，天天向上  
-2 第二章  职位设置与职责  
第五条   个金客户经理职位设置为：客户经理助理、客户经理、
高级客户经理、资深客户经理。  
第六条   个金客户经理的基本职责：  
（一）   客户开发。研究客户信息、联系与选择客户、与客户建
立相互依存、相互支持的业务往来关系，扩大业务资源，创造良好业
绩； 
（二）业务创新与产品营销。把握市场竞争变化方向，开展市场
与客户需 求的调研，对业务产品及服务进行创新；设计客户需求的产
品组合、制订和实施市场营销方案；  
（三）客户服务。负责我行各类表内外授信业务及中间业务的受
理和运作，进行综合性、整体性的客户服务；  
（四）防范风险，提高收益。提升风险防范意识及能力，提高经
营产品质量；  
（五）培养人材。在提高自身综合素质的同时，发扬团队精神，
培养后备业务骨干。  
 百度文库  - 好好学习，天天向上  
-3 第三章  基础素质要求  
第七条   个金客户经理准入条件：  
（一）工作经历：须具备大专以上学历，至少二年以上银行工作
经验。  
（二）工作能力：熟悉我行的各项业务，了解市场情况，熟悉各
类客户的金融需求，熟悉个人理财工具，有一定的业务管理和客户管
理能力。  
（三）工作业绩：个金客户经理均应达到相应等级的准入标准。
该标准可根据全行整体情况由考核部门进行调整。  
（四）专业培训：个金客户经理应参加有关部门组织的专业培训
并通过业务考试。  
（五）符合分行人事管理和专业管理的要求。  
第四章  个人业绩考核标准  
第八条   个金客户经理个人业绩以储蓄季日均、季有效净增发卡
量、季净增个贷余额 三项业务为主要考核指标，实行季度考核。具体
标准如下：  


类别 行员级别 考核分值 准入标准  
储蓄业务 个贷业务 卡业务 
客户经理助理  5 90 300万  500张 
4 95  百度文库  - 好好学习，天天向上  
-4 3 100  
2 105  
1 110  
客户经理 5 115 300万  500张 
4 120  
3 125  
2 130  
1 135  
高级客户经理  5 140 500万 800万  
4 145  
3 150  
2 155  
1 160  
资深客户经理  5 165 500万 800万  
4 170  
3 175  
2 180  
1 185  
说明： 1.储蓄业务（季日均余额）为各类个金客户经理考核进入的最低标准。   
2.卡业务（季新增发有效卡量）为见习、 D类、初级客户经理进入的最低标准。  
3.有效卡的概念：每张卡月均余额为 100元以上。  
4.个贷业务（季新增发放个贷）为中级以上客户经理考核进入的最低标准。  
5.超出最低考核标准可相互折算，折算标准： 50万储蓄 =50万个贷 =50张有效卡 =5分（折算以 5分为单位）  

 百度文库  - 好好学习，天天向上  
-5 第五章  工作质量考核标准  
第九条   工作质量考核实行扣分制。工作质量指个金客户经理在
从事所有个人业务时出现投诉、差错及风险。该项考核最多扣 50分，
如发生重大差错事故，按分行有关制度处理。  
（一）服务质量考核：   
1、工作责任心不强，缺乏配合协作精神；扣 5分 
2、客户服务效率低，态度生硬或不及时为客户提供维护服务，
有客户投诉的 ,每投诉一次扣 2分 
3、不服从支行工作安排，不认真参加分（支）行宣传活动的，
每次扣 2分； 
4、未能及时参加分行（支行）组织的各种业务培训、考试和专
题活动的每次扣 2分； 
5、未按规定要求进行贷前调查、贷后检查工作的，每笔扣 5分； 
6、未建立信贷台帐资料及档案的每笔扣 5分； 
7、在工作中有不廉洁自律情况的每发现一次扣 50分。 
（二）个人资产质量考核：  
当季考核收息率 97%以上为合格，每降 1个百分点扣 2分；不
良资产零为合格，每超一个个百分点扣 1分。 
A.发生跨月逾期，单笔不超过 10万元，当季收回者，扣 1分。 
B.发生跨月逾期， 2笔以上累计金额不超过 20万元，当季收回
者，扣 2分；累计超过 20万元以上的，扣 4分。 百度文库  - 好好学习，天天向上  
-6 C.发生逾期超过 3个月，无论金额大小和笔数，扣 10分。 

第六章  聘任考核程序  
第十条   凡达到本办法第三章规定的该技术职务所要求的行内职
工，都可向分行人力资源部申报个金客户经理评聘。  
第十一条   每年一月份为客户经理评聘的申报时间，由分行人力
资源部、个人业务部每年二月份组织统一的资格考试。考试合格者由
分行颁发个金客户经理资格证书，其有效期为一年。  
第十二条   客户经理聘任实行开放式、浮动制，即：本人申报  —
— 所在部门推荐  —— 分行考核  —— 行长聘任  —— 每年考评
调整浮动。   
第十三条   特别聘任：  
（一）经分行同意录用从其他单位调入的个金客户经理，由用人
单位按 D类人员进行考核， 薪资待遇按其业绩享受行内正式行员工同
等待遇。待正式转正后按第十一条规定申报技术职务。  
（二）对为我行业务创新、工作业绩等方面做出重大贡献的市场
人员经支行推荐、分行行长 批准可越级聘任。  
第十四条   对于创利业绩较高，而暂未入围技术职务系列，或所
评聘技术职务较低的市场人员，各级领导要加大培养力度，使其尽快百度文库  - 好好学习，天天向上  
-7 入围，并由所在行制定临时奖励办法。  

第七章   考核待遇  
第十五条   个人金融业务客户经理的收入基本由三部分组成： 客
户经理等级基本收入、业绩奖励收入和日常工作绩效收入。  
客户经理等级基本收入是指客户经理的每月基本收入， 基本分为
助理客户经理、客户经理、高级客户经理和资深客户经理四大层面，
在每一层面分为若干等级。  
客户经理的等级标准由客户经理在上年的业绩为核定标准， 如果
客户经理在我行第一次进行客户经理评级， 以客户经理自我评价为主
要依据，结合客户经理以往工作经验，由个人金融部、人事部门共同
最终决定客户经理的等级。  
助理客户经理待遇按照人事部门对主办科员以下人员的待遇标
准；客户经理待遇按照人事部门对主办科员的待遇标准；高级客户经
理待遇按照人事部门对付科级的待遇标准； 资深客户经理待遇 按照人
事部门对正科级的待遇标准。  
业绩奖励收入是指客户经理每个业绩考核期间的实际业绩所给
与兑现的奖金部分。  
日常工作绩效收入是按照个金客户经理所从事的事务性工作进
行定量化考核，经过工作的完成情况进行奖金分配。该项奖金主要由
个人金融部总经理和各支行的行长其从事个人金融业务的人员进行
分配，主要侧重分配于从事个金业务的基础工作和创新工作。  百度文库  - 好好学习，天天向上  
-8 第十五条   各项考核分值总计达到某一档行员级别考核分值标
准，个金客户经理即可在下一季度享受该级行员的薪资标准。下一季
度考核时，按照已享受行员级别考核折算比值进行考核，以次类推。  
第十六条   对已聘为各级客户经理的人员，当工作业绩考核达不
到相应技术职务要求下限时，下一年技术职务相应下调 。 
第十七条   为保护个人业务客户经理创业的积极性，暂定其收入
构成中基础薪点不低于 40%。 

第八章  管理与奖惩  
第十八条   个金客户经理管理机构为分行客户经理管理委员会。
管理委员会组成人员：行长或主管业务副行长，个人业务部、人力资
源部、风险管理部负责人。  
第十九条   客户经理申报的各种信息必须真实。分行个人业务部
需对其工作业绩数据进行核实，并对其真实性负责；分行人事部门需
对其学历、工作阅历等基本信息进行核实，并对其真实性负责。  
第二十条   对因工作不负责任使资产质量产生严重风险或造成损
失的给予降级直至开 除处分，构成渎职罪的提请司法部门追究刑事责
任。 
 百度文库  - 好好学习，天天向上  
-9 第九章  附    则 
第二十一条   本办法自发布之日起执行。  
第二十二条   本办法由上海浦东发展银行西安分行行负责解释和
修改。  
  char_page_mapping= [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9, 9]
```

##### 2、向量数据库构建

使用`DashScopeEmbeddings`将文本块转换为向量表示，然后使用FAISS向量数据库存储文本向量，支持高效的相似度搜索。为每个文本块保存对应的页码信息，实现查询结果溯源。

**2.1、下载需要的包：**

```shell
pip install langchain_community
pip install langchain-text-splitters
pip install dashscope
pip install faiss-cpu
# pip install faiss-gpu
```

**2.2、处理文本并存储向量数据库：**

```python
# ...
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
import os
import pickle

# ...

# 设置AK
DASHSCOPE_API_KEY = "sk-xxxxxxxxxxxxxxxxxxxxxxxxx"

def process_text_with_splitter(text: str, char_page_mapping: List[int], save_path: str = None) -> FAISS:
    """
    处理文本并创建向量存储

    参数:
        text: 提取的文本内容
        char_page_mapping: 每个字符对应的页码列表
        save_path: 可选，保存向量数据库的路径

    返回:
        knowledgeBase: 基于FAISS的向量存储对象
    """
    # 创建文本分割器，用于将长文本分割成小块
    text_splitter = RecursiveCharacterTextSplitter(
        separators=["\n\n", "\n", ".", " ", ""],
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
    )

    # 分割文本
    chunks = text_splitter.split_text(text)
    print(f"文本被分割成 {len(chunks)} 个块。")

    # 创建嵌入模型
    embeddings = DashScopeEmbeddings(
        model="text-embedding-v1",
        dashscope_api_key=DASHSCOPE_API_KEY,
    )

    # 从文本块创建知识库
    knowledgeBase = FAISS.from_texts(chunks, embeddings)
    print("已从文本块创建知识库。")

    # 为每个文本块找到对应的页码信息
    page_info = {}
    current_pos = 0

    for chunk in chunks:
        chunk_start = current_pos
        chunk_end = current_pos + len(chunk)

        # 找到这个文本块中字符对应的页码
        chunk_pages = char_page_mapping[chunk_start:chunk_end]

        # 取页码的众数（出现最多的页码）作为该块的页码
        if chunk_pages:
            # 统计每个页码出现的次数
            page_counts = {}
            for page in chunk_pages:
                page_counts[page] = page_counts.get(page, 0) + 1

            # 找到出现次数最多的页码
            most_common_page = max(page_counts, key=page_counts.get)
            page_info[chunk] = most_common_page
        else:
            page_info[chunk] = 1  # 默认页码

        current_pos = chunk_end

    knowledgeBase.page_info = page_info
    print(f'页码映射完成，共 {len(page_info)} 个文本块')

    # 如果提供了保存路径，则保存向量数据库和页码信息
    if save_path:
        # 确保目录存在
        os.makedirs(save_path, exist_ok=True)

        # 保存FAISS向量数据库
        knowledgeBase.save_local(save_path)
        print(f"向量数据库已保存到: {save_path}")

        # 保存页码信息到同一目录
        with open(os.path.join(save_path, "page_info.pkl"), "wb") as f:
            pickle.dump(page_info, f)
        print(f"页码信息已保存到: {os.path.join(save_path, 'page_info.pkl')}")

    return knowledgeBase

# 读取PDF文件
pdf_reader = PdfReader('./浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf')
# 提取文本和页码信息
text, char_page_mapping = extract_text_with_page_numbers(pdf_reader)
# print('text=',text,'char_page_mapping=',char_page_mapping)

print(f"提取的文本长度: {len(text)} 个字符。")

# 处理文本并创建知识库，同时保存到磁盘
save_dir = "./vector_db"
knowledgeBase = process_text_with_splitter(text, char_page_mapping, save_path=save_dir)
```

运行结果：

```shell
提取的文本长度: 3881 个字符。
文本被分割成 5 个块。
已从文本块创建知识库。
页码映射完成，共 5 个文本块
向量数据库已保存到: ./vector_db
页码信息已保存到: ./vector_db/page_info.pkl
```

##### 3、语义搜索和问答链

基于用户查询，使用`as_retriever`在向量数据库召回相关文档，可使用`k`参数设置召回chunk数量，并创建问答链。

```python
# ...
def create_rag_qa_chain(knowledge_base, llm):
    """
    基于已有的向量知识库和LLM，创建一个RAG（检索增强生成）问答链。
    参数:
        knowledge_base: 你通过 process_text_with_splitter 创建的 FAISS 向量库
        llm: 已实例化的大语言模型对象，例如 ChatOpenAI()
    返回:
        一个配置好的 LCEL 问答链 (RAG chain)
    """

    # 1. 将向量库转换为检索器，可设置返回的相关文档数量 (k)
    retriever = knowledge_base.as_retriever(search_kwargs={"k": 3})

    # 2. 定义格式化文档的函数（对应旧版的 “stuff” 逻辑）
    def format_docs(docs):
        """将检索到的文档列表合并为单一的上下文字符串。"""
        return "\n\n".join(doc.page_content for doc in docs)

    # 3. 定义提示词模板（这是你可以高度自定义的部分）
    # 这里模拟了Stuff模式，将检索到的所有上下文和问题一起交给模型
    prompt_template = ChatPromptTemplate.from_template(
        """你是一个专业的银行文档分析助手。请严格根据以下提供的上下文信息来回答问题。
        如果上下文中没有明确答案，请直接说“根据提供的资料，无法回答该问题。”，不要编造信息。

        上下文信息：
        {context}

        用户问题：{question}

        请根据上下文给出答案："""
    )

    # 4. 使用 LCEL 组合成链
    # 数据流：问题 -> 检索器 -> 格式化文档 -> 提示词 -> LLM -> 输出解析
    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt_template
        | llm
        | StrOutputParser()
    )

    return rag_chain, retriever
```

##### 4、生成回答

将query和召回文档合并生成回答：

```python
# ...
llm = Tongyi(model_name="deepseek-v3", dashscope_api_key=DASHSCOPE_API_KEY) # qwen-turbo
# 创建链
qa_chain, retriever = create_rag_qa_chain(knowledgeBase, llm)

# 进行问答
question = "个金客户经理的考核指标有哪些？"
answer = qa_chain.invoke(question)
print(f"问题：{question}")
print(f"答案：{answer}")

# 查看检索到的原文片段（用于调试）
print("\n检索到的相关原文：")
docs = retriever.invoke(question)
for i, doc in enumerate(docs):
    print(f"[片段{i+1}]: {doc.page_content[:200]}...")  # 打印前200字符
```

执行结果：

```shell
提取的文本长度: 3881 个字符。
文本被分割成 5 个块。
已从文本块创建知识库。
页码映射完成，共 5 个文本块
向量数据库已保存到: ./vector_db
页码信息已保存到: ./vector_db/page_info.pkl
问题：个金客户经理的考核指标有哪些？
答案：个金客户经理的考核指标分为两大类：个人业绩考核和工作质量考核。

1. **个人业绩考核**：以储蓄季日均余额、季有效净增发卡量、季净增个贷余额三项业务为主要考核指标，实行季度考核。
   - 储蓄业务（季日均余额）
   - 卡业务（季新增发有效卡量），其中有效卡指每张卡月均余额为100元以上
   - 个贷业务（季新增发放个贷）

   超出最低考核标准的部分可相互折算，折算标准为：50万储蓄 = 50万个贷 = 50张有效卡 = 5分（折算以5分为单位）。

2. **工作质量考核**：实行扣分制，主要包括服务质量和服务资产质量两方面：
   - **服务质量考核**包括：
     - 工作责任心不强、缺乏协作精神（扣5分）
     - 客户投诉（每次扣2分）
     - 不服从工作安排或不参加宣传活动（每次扣2分）
     - 未参加培训、考试或专题活动（每次扣2分）
     - 未按规定进行贷前调查、贷后检查（每笔扣5分）
     - 未建立信贷台账及档案（每笔扣5分）
     - 不廉洁自律行为（每次扣50分）
   - **个人资产质量考核**：
     - 收息率低于97%，每降1个百分点扣2分
     - 不良资产超过零，每超一个百分点扣1分
     - 发生跨月逾期等情况也按具体规定扣分（如逾期超过3个月扣10分等）

综上，考核内容涵盖业绩与质量两个维度，且实行季度和年度相结合的动态管理机制。

检索到的相关原文：
[片段1]: 百度文库  - 好好学习，天天向上  
-1 上海浦东发展银行西安分行  
个金客户经理管理考核暂行办法  


第一章  总   则 
第一条   为保证我分行个金客户经理制的顺利实施，有效调动个
金客户经理的积极性，促进个金业务快速、稳定地发展，根据总行《上
海浦东发展银行个人金融营销体系建设方案（试行）》要求，特制定
《上海浦东发展银行西安分行个金客户经理管理考核暂行办法（试
行）》（以...
[片段2]: 培养后备业务骨干。  
 百度文库  - 好好学习，天天向上  
-3 第三章  基础素质要求  
第七条   个金客户经理准入条件：  
（一）工作经历：须具备大专以上学历，至少二年以上银行工作
经验。  
（二）工作能力：熟悉我行的各项业务，了解市场情况，熟悉各
类客户的金融需求，熟悉个人理财工具，有一定的业务管理和客户管
理能力。  
（三）工作业绩：个金客户经理均应达到相应等级的准入标准。...
[片段3]: 5.超出最低考核标准可相互折算，折算标准： 50万储蓄 =50万个贷 =50张有效卡 =5分（折算以 5分为单位）  

 百度文库  - 好好学习，天天向上  
-5 第五章  工作质量考核标准  
第九条   工作质量考核实行扣分制。工作质量指个金客户经理在
从事所有个人业务时出现投诉、差错及风险。该项考核最多扣 50分，
如发生重大差错事故，按分行有关制度处理。  
（一）服务质量考核： ...
```

##### 完整代码：

```python
from PyPDF2 import PdfReader
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.runnables import RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_community.vectorstores import FAISS
from langchain_community.embeddings import DashScopeEmbeddings
from typing import List, Tuple
import os
import pickle
from langchain_community.llms import Tongyi

DASHSCOPE_API_KEY = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

def extract_text_with_page_numbers(pdf) -> Tuple[str, List[Tuple[str, int]]]:
    """
    从PDF中提取文本并记录每个字符对应的页码

    参数:
        pdf: PDF文件对象

    返回:
        text: 提取的文本内容
        char_page_mapping: 每个字符对应的页码列表
    """
    text = ""
    char_page_mapping = []

    for page_number, page in enumerate(pdf.pages, start=1):
        extracted_text = page.extract_text()
        if extracted_text:
            text += extracted_text
            # 为当前页面的每个字符记录页码
            char_page_mapping.extend([page_number] * len(extracted_text))
        else:
            print(f"No text found on page {page_number}.")

    return text, char_page_mapping

def process_text_with_splitter(text: str, char_page_mapping: List[int], save_path: str = None) -> FAISS:
    """
    处理文本并创建向量存储

    参数:
        text: 提取的文本内容
        char_page_mapping: 每个字符对应的页码列表
        save_path: 可选，保存向量数据库的路径

    返回:
        knowledgeBase: 基于FAISS的向量存储对象
    """
    # 创建文本分割器，用于将长文本分割成小块
    text_splitter = RecursiveCharacterTextSplitter(
        separators=["\n\n", "\n", ".", " ", ""],
        chunk_size=1000,
        chunk_overlap=200,
        length_function=len,
    )

    # 分割文本
    chunks = text_splitter.split_text(text)
    print(f"文本被分割成 {len(chunks)} 个块。")

    # 创建嵌入模型
    embeddings = DashScopeEmbeddings(
        model="text-embedding-v1",
        dashscope_api_key=DASHSCOPE_API_KEY,
    )

    # 从文本块创建知识库
    knowledgeBase = FAISS.from_texts(chunks, embeddings)
    print("已从文本块创建知识库。")

    # 为每个文本块找到对应的页码信息
    page_info = {}
    current_pos = 0

    for chunk in chunks:
        chunk_start = current_pos
        chunk_end = current_pos + len(chunk)

        # 找到这个文本块中字符对应的页码
        chunk_pages = char_page_mapping[chunk_start:chunk_end]

        # 取页码的众数（出现最多的页码）作为该块的页码
        if chunk_pages:
            # 统计每个页码出现的次数
            page_counts = {}
            for page in chunk_pages:
                page_counts[page] = page_counts.get(page, 0) + 1

            # 找到出现次数最多的页码
            most_common_page = max(page_counts, key=page_counts.get)
            page_info[chunk] = most_common_page
        else:
            page_info[chunk] = 1  # 默认页码

        current_pos = chunk_end

    knowledgeBase.page_info = page_info
    print(f'页码映射完成，共 {len(page_info)} 个文本块')

    # 如果提供了保存路径，则保存向量数据库和页码信息
    if save_path:
        # 确保目录存在
        os.makedirs(save_path, exist_ok=True)

        # 保存FAISS向量数据库
        knowledgeBase.save_local(save_path)
        print(f"向量数据库已保存到: {save_path}")

        # 保存页码信息到同一目录
        with open(os.path.join(save_path, "page_info.pkl"), "wb") as f:
            pickle.dump(page_info, f)
        print(f"页码信息已保存到: {os.path.join(save_path, 'page_info.pkl')}")

    return knowledgeBase

def load_knowledge_base(load_path: str, embeddings = None) -> FAISS:
    """
    从磁盘加载向量数据库和页码信息

    参数:
        load_path: 向量数据库的保存路径
        embeddings: 可选，嵌入模型。如果为None，将创建一个新的DashScopeEmbeddings实例

    返回:
        knowledgeBase: 加载的FAISS向量数据库对象
    """
    # 如果没有提供嵌入模型，则创建一个新的
    if embeddings is None:
        embeddings = DashScopeEmbeddings(
            model="text-embedding-v1",
            dashscope_api_key=DASHSCOPE_API_KEY,
        )

    # 加载FAISS向量数据库，添加allow_dangerous_deserialization=True参数以允许反序列化
    knowledgeBase = FAISS.load_local(load_path, embeddings, allow_dangerous_deserialization=True)
    print(f"向量数据库已从 {load_path} 加载。")

    # 加载页码信息
    page_info_path = os.path.join(load_path, "page_info.pkl")
    if os.path.exists(page_info_path):
        with open(page_info_path, "rb") as f:
            page_info = pickle.load(f)
        knowledgeBase.page_info = page_info
        print("页码信息已加载。")
    else:
        print("警告: 未找到页码信息文件。")

    return knowledgeBase

# 读取PDF文件
pdf_reader = PdfReader('./浦发上海浦东发展银行西安分行个金客户经理考核办法.pdf')
# 提取文本和页码信息
text, char_page_mapping = extract_text_with_page_numbers(pdf_reader)
# print('text=',text,'char_page_mapping=',char_page_mapping)

print(f"提取的文本长度: {len(text)} 个字符。")

# 处理文本并创建知识库，同时保存到磁盘
save_dir = "./vector_db"
knowledgeBase = process_text_with_splitter(text, char_page_mapping, save_path=save_dir)

llm = Tongyi(model_name="deepseek-v3", dashscope_api_key=DASHSCOPE_API_KEY) # qwen-turbo

def create_rag_qa_chain(knowledge_base, llm):
    """
    基于已有的向量知识库和LLM，创建一个RAG（检索增强生成）问答链。
    参数:
        knowledge_base: 你通过 process_text_with_splitter 创建的 FAISS 向量库
        llm: 已实例化的大语言模型对象，例如 ChatOpenAI()
    返回:
        一个配置好的 LCEL 问答链 (RAG chain)
    """

    # 1. 将向量库转换为检索器，可设置返回的相关文档数量 (k)
    retriever = knowledge_base.as_retriever(search_kwargs={"k": 3})

    # 2. 定义格式化文档的函数（对应旧版的 “stuff” 逻辑）
    def format_docs(docs):
        """将检索到的文档列表合并为单一的上下文字符串。"""
        return "\n\n".join(doc.page_content for doc in docs)

    # 3. 定义提示词模板（这是你可以高度自定义的部分）
    # 这里模拟了Stuff模式，将检索到的所有上下文和问题一起交给模型
    prompt_template = ChatPromptTemplate.from_template(
        """你是一个专业的银行文档分析助手。请严格根据以下提供的上下文信息来回答问题。
        如果上下文中没有明确答案，请直接说“根据提供的资料，无法回答该问题。”，不要编造信息。

        上下文信息：
        {context}

        用户问题：{question}

        请根据上下文给出答案："""
    )

    # 4. 使用 LCEL 组合成链
    # 数据流：问题 -> 检索器 -> 格式化文档 -> 提示词 -> LLM -> 输出解析
    rag_chain = (
        {"context": retriever | format_docs, "question": RunnablePassthrough()}
        | prompt_template
        | llm
        | StrOutputParser()
    )

    return rag_chain, retriever

# 创建链
qa_chain, retriever = create_rag_qa_chain(knowledgeBase, llm)

# 进行问答
question = "个金客户经理的考核指标有哪些？"
answer = qa_chain.invoke(question)
print(f"问题：{question}")
print(f"答案：{answer}")

# 可选：查看检索到的原文片段（用于调试）
print("\n检索到的相关原文：")
docs = retriever.invoke(question)
for i, doc in enumerate(docs):
    print(f"[片段{i+1}]: {doc.page_content[:200]}...")  # 打印前200字符
```

### LangChain问答链

LangChain是一个专门为构建基于大语言模型（LLM）的应用而设计的框架，由python语言开发。可以理解成大语言模型应用开发工具箱，里面集成了很多的工具。

LangChain问答链（Question-Answering Chain）是LangChain工具箱中的工具。它是一个预定义的流程：

> 输入用户问题 → (可选)查找相关文本 → 利用LLM生成回答

LangChain问答链有很多的模式，如下：

##### 1、stuff

直接把文档作为prompt输入给OpenAI。

##### 2、map_reduce

对于每个chunk做一个prompt（回答或者摘要），然后再做合并。

##### 3、refine

在第一个chunk上做prompt得到结果，然后合并下一个文件再输出结果。

##### 4、map_rerank

对每个chunk做prompt，然后打个分，然后根据分数返回最好的文档中的结果。

### RAG在LLM各个阶段的应用

##### 1、NativeRAG

原生RAG，不依赖LangChain框架，以更加底层的方式实现检索增强回答。

> 用户提问 → 检索向量数据库 → 将用户提问和检索到的chunks拼装成prompt → 发送给LLM → 输出回答。

**依赖的技术栈：**

- 文本提取工具：将数据提取出来，如PyPDF2。

- 数据切分并转成向量：Embedding模型。

- 存入本地向量数据库：Faiss等。

- 调用LLM。

上面讲解的RAG就是NativeRAG。

##### 2、RAFT

`Retrieval-Augmented Fine-Tuning`，即检索增强微调。它是RAG的进阶版本，让模型在微调过程中学习知识库的表达和提问方式。

相比RAG来说，RAG是将检索到的知识当做prompt给LLM，相当于外挂数据库。

而RAFT是在模型训练阶段中实现的，构建带检索上下文的训练样本，然后进行微调得到更强的LLM模型。

> 构建带检索上下文的训练样本 → 微调LLM（SFT-监督学习）→ 得到更强的LLM → 仍然可以外挂RAG

RAFT 是将检索增强的能力通过微调“融入模型本身”的技术，是RAG的高阶形态。

**RAG和RAFT对比：**

| 特性       | RAG   | RAFT    | RAG + RAFT |
| -------- | ----- | ------- | ---------- |
| 是否需要微调模型 | ❌ 不需要 | ✅ 需要    | 可选         |
| 知识更新速度   | 快     | 慢（重新训练） | 快          |
| 表达一致性    | 一般    | 强       | 很强         |
| 领域专业性    | 中     | 强       | 最强         |

# Query改写

RAG的核心在于”检索-生成“，如果在第一步”检索“就走偏了，那么后续的”生成“质量会降低。用户提供的问题往往是口语化的、承接上下文的、模糊的、甚至是带有情绪的。

而知识库中的文本（chunks）通常是陈述性的、客观的。

所以需要一个翻译官将用户“口语化查询”转换为“书面化、精确的检索语句”。

### 1、上下文依赖型改写

对于用户提问需要依赖上下文的，需要结合上下文进行重新修改形成新的提示词

```css
# 对话历史:
用户: "我想了解一下上海迪士尼乐园的最新项目。"
AI: "上海迪士尼乐园最新推出了'疯狂动物城'主题园区，这里有朱迪警官和尼克狐的互动体验。"
用户: "这个园区有什么游乐设施？"
AI: "'疯狂动物城'园区目前有疯狂动物城警察局、朱迪警官训练营和尼克狐的冰淇淋店等设施。"

# 当前查询：
用户：还有其他设施吗？
```

代码：

```python
import dashscope
dashscope.api_key = "xxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# 基于 prompt 生成文本
def get_completion(prompt, model="qwen-turbo-latest"):
    messages = [{"role": "user", "content": prompt}]
    response = dashscope.Generation.call(
        model=model,
        messages=messages,
        result_format="message",
        temperature=0,#温度设置为0
    )
    return response.output.choices[0].message.content

# Query改写功能
class QueryRewriter:
    def __init__(self, model="qwen-turbo-latest"):
        self.model = model

    # 实现上下文相关的查询改写逻辑
    def rewrite_context_dependent_query(self, current_query, conversation_history):
        """上下文依赖型Query改写"""
        instruction = """
你是一个智能的查询优化助手。请分析用户的当前问题以及前序对话历史，判断当前问题是否依赖于上下文。
如果依赖，请将当前问题改写成一个独立的、包含所有必要上下文信息的完整问题。
如果不依赖，直接返回原问题。
        """

        prompt = f"""
### 指令 ###
{instruction}

### 对话历史 ###
{conversation_history}

### 当前问题 ###
{current_query}

### 改写后的问题 ###
"""
        return get_completion(prompt, self.model)

def main():
    # 初始化Query改写器
    rewriter = QueryRewriter()

    # 示例1: 上下文依赖型Query
    print("示例1: 上下文依赖型Query")
    conversation_history = """
用户: "我想了解一下上海迪士尼乐园的最新项目。"
AI: "上海迪士尼乐园最新推出了'疯狂动物城'主题园区，这里有朱迪警官和尼克狐的互动体验。"
用户: "这个园区有什么游乐设施？"
AI: "'疯狂动物城'园区目前有疯狂动物城警察局、朱迪警官训练营和尼克狐的冰淇淋店等设施。"
"""
    current_query = "还有其他设施吗？"

    print(f"对话历史: {conversation_history}")
    print(f"当前查询: {current_query}")

    result = rewriter.rewrite_context_dependent_query(current_query, conversation_history)
    print(f"改写结果: {result}\n")

if __name__ == '__main__':
    main()
```

执行结果：

```shell
示例1: 上下文依赖型Query
对话历史: 
用户: "我想了解一下上海迪士尼乐园的最新项目。"
AI: "上海迪士尼乐园最新推出了'疯狂动物城'主题园区，这里有朱迪警官和尼克狐的互动体验。"
用户: "这个园区有什么游乐设施？"
AI: "'疯狂动物城'园区目前有疯狂动物城警察局、朱迪警官训练营和尼克狐的冰淇淋店等设施。"

当前查询: 还有其他设施吗？
# 改写之后的新提示词结合了上下文并给出了新的提示词
改写结果: 除了疯狂动物城警察局、朱迪警官训练营和尼克狐的冰淇淋店之外，'疯狂动物城'园区还有其他游乐设施吗？
```

### 对比型改写

对于用户提问的是比较的意思，需要结合上下文将具体的对比对象找到，并形成新的提示词

```css
# 历史对话：

用户: "我想了解一下上海迪士尼乐园的最新项目。"
AI: "上海迪士尼乐园最新推出了疯狂动物城主题园区，还有蜘蛛侠主题园区"

# 当前查询：
用户：哪个游玩的时间比较长，比较有趣？
```

代码：

```python
# ...
# Query改写功能
class QueryRewriter:
    # ...
    # 实现对比型查询改写逻辑
    def rewrite_comparative_query(self, query, context_info):
        """对比型Query改写"""
        instruction = """
你是一个查询分析专家。请分析用户的输入和相关的对话上下文，识别出问题中需要进行比较的多个对象。
然后，将原始问题改写成一个更明确、更适合在知识库中检索的对比性查询。
        """

        prompt = f"""
### 指令 ###
{instruction}

### 对话历史/上下文信息 ###
{context_info}

### 原始问题 ###
{query}

### 改写后的查询 ###
"""
        return get_completion(prompt, self.model)

def main():
    # 初始化Query改写器
    rewriter = QueryRewriter()
    # 示例2: 对比型Query
    print("示例2: 对比型Query")
    query = "哪个游玩的时间比较长，比较有趣"
    context_info = """
用户: "我想了解一下上海迪士尼乐园的最新项目。"
AI: "上海迪士尼乐园最新推出了疯狂动物城主题园区，还有蜘蛛侠主题园区"
"""
    print(f"历史对话: {conversation_history}")
    print(f"当前查询: {query}")
    result = rewriter.rewrite_comparative_query(query, context_info)
    print(f"改写结果: {result}\n")
```

执行结果：

```shell
示例2: 对比型Query
历史对话: 
用户: "我想了解一下上海迪士尼乐园的最新项目。"
AI: "上海迪士尼乐园最新推出了'疯狂动物城'主题园区，这里有朱迪警官和尼克狐的互动体验。"
用户: "这个园区有什么游乐设施？"
AI: "'疯狂动物城'园区目前有疯狂动物城警察局、朱迪警官训练营和尼克狐的冰淇淋店等设施。"

当前查询: 哪个游玩的时间比较长，比较有趣
改写结果: 改写后的查询：  
“上海迪士尼乐园的疯狂动物城主题园区和蜘蛛侠主题园区，哪个游玩时间更长、体验更有趣？”
```

### 模糊指代型改写

当用户提问出现模糊指代的字眼，比如”他“、”它“....，需要结合上下文将模糊代指的具体对象找到。

```css
# 历史会话：
用户: "我想了解一下上海迪士尼乐园和香港迪士尼乐园的烟花表演。"
AI: "好的，上海迪士尼乐园和香港迪士尼乐园都有精彩的烟花表演。"

# 当前查询：
用户：都什么时候开始？
```

代码：

```python
# ...
# Query改写功能
class QueryRewriter:
    # ...
    # 模糊指代型Query改写
    def rewrite_ambiguous_reference_query(self, current_query, conversation_history):
        """不明确引用型Query改写"""
        instruction = """
你是一个消除语言歧义的专家。请分析用户的当前问题和对话历史，找出问题中 "都"、"它"、"这个" 等模糊指代词具体指向的对象。
然后，将这些指代词替换为明确的对象名称，生成一个清晰、无歧义的新问题。
        """

        prompt = f"""
### 指令 ###
{instruction}

### 对话历史 ###
{conversation_history}

### 当前问题 ###
{current_query}

### 改写后的问题 ###
"""
        return get_completion(prompt, self.model)

def main():
    # 初始化Query改写器
    rewriter = QueryRewriter()
    # 示例3: 模糊指代型Query
    print("示例3: 模糊指代型Query")
    current_query = "都什么时候开始？"
    conversation_history = """
用户: "我想了解一下上海迪士尼乐园和香港迪士尼乐园的烟花表演。"
AI: "好的，上海迪士尼乐园和香港迪士尼乐园都有精彩的烟花表演。"
"""
    print(f"对话历史: {conversation_history}")
    print(f"当前查询: {current_query}")
    result = rewriter.rewrite_ambiguous_reference_query(current_query, conversation_history)
    print(f"改写结果: {result}\n")
```

运行结果：

```shell
示例3: 模糊指代型Query
对话历史: 
用户: "我想了解一下上海迪士尼乐园和香港迪士尼乐园的烟花表演。"
AI: "好的，上海迪士尼乐园和香港迪士尼乐园都有精彩的烟花表演。"

当前查询: 都什么时候开始？
改写结果: 上海迪士尼乐园和香港迪士尼乐园的烟花表演都什么时候开始？
```

### 多意图型改写

对于用户提问中有多个问题时，需要将多个问题拆分成多个问题。

```css
# 当前查询：
用户：门票多少钱？需要提前预约吗？停车费怎么收？
```

代码：

```python
# ...
# Query改写功能
class QueryRewriter:
    # ...
    # 多意图型Query改写 - 分解查询
    def rewrite_multi_intent_query(self, query):
        """多意图型Query改写 - 分解查询"""
        instruction = """
你是一个任务分解机器人。请将用户的复杂问题分解成多个独立的、可以单独回答的简单问题。以JSON数组格式输出。
        """

        prompt = f"""
### 指令 ###
{instruction}

### 原始问题 ###
{query}

### 分解后的问题列表 ###
请以JSON数组格式输出，例如：["问题1", "问题2", "问题3"]
"""
        return get_completion(prompt, self.model)

def main():
    # 初始化Query改写器
    rewriter = QueryRewriter()
    # 示例4: 多意图型Query - 分解查询
    print("示例4: 多意图型Query")
    query = "门票多少钱？需要提前预约吗？停车费怎么收？"
    print(f"当前查询: {query}")
    result = rewriter.rewrite_multi_intent_query(query)
    print(f"分解后的当前查询列表: {result}\n")
```

执行结果：

```shell
示例4: 多意图型Query
当前查询: 门票多少钱？需要提前预约吗？停车费怎么收？
分解后的当前查询列表: [
  "门票多少钱？",
  "需要提前预约吗？",
  "停车费怎么收？"
]
```

### 反问型改写

用户提问可能会带有情绪，可能会有反话，所以需要将其改写成一个中立、客观的问题。

```css
# 历史会话：
用户: "你好，我想预订下周六上海迪士尼乐园的门票。"
AI: "正在为您查询... 查询到下周六的门票已经售罄。"
用户: "售罄是什么意思？我朋友上周去还能买到当天的票。"

# 当前查询：
用户：这不会也要提前一个月预订吧？
```

代码：

```python
# ...
# Query改写功能
class QueryRewriter:
    # ...
    # 反问型Query改写
    def rewrite_negative_query(self, current_query, conversation_history):
        """反问型Query改写"""
        instruction = """
你是一个沟通理解大师。请分析用户的反问或带有情绪的陈述，识别其背后真实的意图和问题。
然后，将这个反问改写成一个中立、客观、可以直接用于知识库检索的问题。
        """

        prompt = f"""
### 指令 ###
{instruction}

### 对话历史 ###
{conversation_history}

### 当前问题 ###
{current_query}

### 改写后的问题 ###
"""
        return get_completion(prompt, self.model)

def main():
    # 初始化Query改写器
    rewriter = QueryRewriter()
    # 示例5: 反问型Query
    print("示例5: 反问型Query")
    current_query = "这不会也要提前一个月预订吧？"
    conversation_history = """
用户: "你好，我想预订下周六上海迪士尼乐园的门票。"
AI: "正在为您查询... 查询到下周六的门票已经售罄。"
用户: "售罄是什么意思？我朋友上周去还能买到当天的票。"
"""
    print(f"对话历史: {conversation_history}")
    print(f"当前查询: {current_query}")
    result = rewriter.rewrite_negative_query(current_query, conversation_history)
    print(f"改写结果: {result}\n")
```

运行结果：

```shell
示例5: 反问型Query
对话历史: 
用户: "你好，我想预订下周六上海迪士尼乐园的门票。"
AI: "正在为您查询... 查询到下周六的门票已经售罄。"
用户: "售罄是什么意思？我朋友上周去还能买到当天的票。"

当前查询: 这不会也要提前一个月预订吧？
改写结果: 迪士尼乐园门票是否需要提前一个月预订？示例5: 反问型Query
对话历史: 
用户: "你好，我想预订下周六上海迪士尼乐园的门票。"
AI: "正在为您查询... 查询到下周六的门票已经售罄。"
用户: "售罄是什么意思？我朋友上周去还能买到当天的票。"

当前查询: 这不会也要提前一个月预订吧？
改写结果: 迪士尼乐园门票是否需要提前一个月预订？
```

### 自动识别类型（意图识别）

基于用户提问自动识别类型，然后区分类型对提问进行改写。

代码：

```python
# ...
# Query改写功能
class QueryRewriter:
    # ...
    # 自动识别类型并query改写
    def auto_rewrite_query(self, query, conversation_history = "", context_info = ""):
        """自动识别类型并query改写"""
        instruction = instruction = """
你是一个智能的查询分析专家。请分析用户的查询，识别其属于以下哪种类型：
1. 上下文依赖型 - 包含"还有"、"其他"等需要上下文理解的词汇
2. 对比型 - 包含"哪个"、"比较"、"更"、"哪个更好"、"哪个更"等比较词汇
3. 模糊指代型 - 包含"它"、"他们"、"都"、"这个"等指代词
4. 多意图型 - 包含多个独立问题，用"、"或"？"分隔
5. 反问型 - 包含"不会"、"难道"等反问语气
说明：如果同时存在多意图型、模糊指代型，优先级为多意图型>模糊指代型

请返回JSON格式的结果：
{
    "query_type": "查询类型",
    "rewritten_query": "改写后的查询",
    "confidence": "置信度(0-1)"
}
"""

        prompt = f"""
### 指令 ###
{instruction}

### 对话历史 ###
{conversation_history}

### 上下文信息 ###
{context_info}

### 原始查询 ###
{query}

### 分析结果 ###
"""
        response = get_completion(prompt, self.model)
        try:
            return json.loads(response)
        except:
            return {
                "query_type": "未知类型",
                "rewritten_query": query,
                "confidence": 0.5
            }

def main():
    # 初始化Query改写器
    rewriter = QueryRewriter()
    # 示例6: 自动识别Query类型
    print("示例6: 自动识别Query类型")
    test_queries = [
        "还有其他游乐项目吗？",
        "哪个园区更好玩？",
        "都适合小朋友吗？",
        "有什么餐厅？价格怎么样？",
        "这不会也要排队两小时吧？"
    ]

    for i, query in enumerate(test_queries, 1):
        print(f"测试查询 {i}: {query}")
        result = rewriter.auto_rewrite_query(query)
        print(f"  识别类型: {result['query_type']}")
        print(f"  改写结果: {result['rewritten_query']}")
        print(f"  置信度: {result['confidence']}\n")
```

执行结果：

```shell
示例6: 自动识别Query类型
测试查询 1: 还有其他游乐项目吗？
  识别类型: 上下文依赖型
  改写结果: 除了已知的游乐项目外，还有哪些其他游乐项目？
  置信度: 0.95

测试查询 2: 哪个园区更好玩？
  识别类型: 对比型
  改写结果: 请比较各个园区的趣味性，指出哪个更好玩。
  置信度: 0.95

测试查询 3: 都适合小朋友吗？
  识别类型: 模糊指代型
  改写结果: 哪些产品或活动适合小朋友？
  置信度: 0.95

测试查询 4: 有什么餐厅？价格怎么样？
  识别类型: 多意图型
  改写结果: 有哪些餐厅？这些餐厅的价格怎么样？
  置信度: 0.95

测试查询 5: 这不会也要排队两小时吧？
  识别类型: 反问型
  改写结果: 这需要排队两小时吗？
  置信度: 0.95
```

这里的置信度是LLM给我们的可靠程度，后续我们可以通过一定的规则来判断是否使用该条改写。

### 联网搜索

当用户提问时，如果判断到需要联网搜索，需要进行改写。

| 类型   | 关键词特征               | 示例查询          | 原因说明            |
| ---- | ------------------- | ------------- | --------------- |
| 时效性  | 最新、今天、现在、实时、当前      | 上海迪士尼乐园今天开放吗？ | 需获取当前时间的最新信息    |
| 价格信息 | 多少钱、价格、费用、票价        | 下周六的门票多少钱？    | 价格信息经常变动，需实时查询  |
| 营业信息 | 营业时间、开放时间、闭园时间、是否开放 | 迪士尼乐园现在开门吗？   | 营业状态可能因特殊情况调整   |
| 活动信息 | 活动、表演、演出、节日、庆典      | 最近有什么特别活动？    | 活动信息具有时效性和动态性   |
| 天气信息 | 天气、下雨、温度            | 明天去迪士尼天气怎么样？  | 天气信息需要实时获取      |
| 交通信息 | 怎么去、交通、地铁、公交        | 从浦东机场怎么去迪士尼？  | 交通信息可能因施工、活动等变化 |
| 预订信息 | 预订、预约、购票、订票         | 需要提前多久预订？     | 预订政策可能随时调整      |
| 实时状态 | 排队、拥挤、人流量           | 现在人多不多？       | 实时状态需即时获取       |

##### 1、识别是否需要联网搜索

通过上面的规则定义，让LLM帮忙确实是否需要联网搜索。

```python
def identify_web_search_needs(self, query, conversation_history=""):
        """识别查询是否需要联网搜索"""
        instruction = """
你是一个智能的查询分析专家。请分析用户的查询，判断是否需要联网搜索来获取最新、最准确的信息。

需要联网搜索的情况包括：
1. 时效性信息 - 包含"最新"、"今天"、"现在"、"实时"、"当前"等时间相关词汇
2. 价格信息 - 包含"多少钱"、"价格"、"费用"、"票价"等价格相关词汇
3. 营业信息 - 包含"营业时间"、"开放时间"、"闭园时间"、"是否开放"等营业状态
4. 活动信息 - 包含"活动"、"表演"、"演出"、"节日"、"庆典"等动态信息
5. 天气信息 - 包含"天气"、"下雨"、"温度"等天气相关
6. 交通信息 - 包含"怎么去"、"交通"、"地铁"、"公交"等交通方式
7. 预订信息 - 包含"预订"、"预约"、"购票"、"订票"等预订相关
8. 实时状态 - 包含"排队"、"拥挤"、"人流量"等实时状态

请返回JSON格式：
{
    "need_web_search": true/false,
    "search_reason": "需要搜索的原因",
    "confidence": "置信度(0-1)"
}
"""

        prompt = f"""
### 指令 ###
{instruction}

### 对话历史 ###
{conversation_history}

### 用户查询 ###
{query}

### 分析结果 ###
"""

        response = get_completion(prompt, self.model)
        try:
            return json.loads(response)
        except:
            return {
                "need_web_search": False,
                "search_reason": "无法解析",
                "confidence": 0.5
            }
```

##### 2、为联网搜索改写查询

```python
def rewrite_for_web_search(self, query, search_type="general"):
        """为联网搜索改写查询"""
        instruction = """
你是一个专业的搜索查询优化专家。请将用户的查询改写为更适合搜索引擎检索的形式。

改写技巧：
1. 添加具体地点 - 如"上海迪士尼乐园"、"香港迪士尼乐园"
2. 添加时间范围 - 如"2024年"、"今天"、"本周"
3. 使用关键词组合 - 将长句拆分为关键词
4. 添加搜索意图 - 明确搜索目的
5. 去除口语化表达 - 转换为标准搜索词
6. 添加相关词汇 - 增加同义词或相关词

请返回JSON格式：
{
    "rewritten_query": "改写后的搜索查询",
    "search_keywords": ["关键词1", "关键词2", "关键词3"],
    "search_intent": "搜索意图",
    "suggested_sources": ["建议搜索的网站类型"]
}
"""

        prompt = f"""
### 指令 ###
{instruction}

### 原始查询 ###
{query}

### 搜索类型 ###
{search_type}

### 改写结果 ###
"""

        response = get_completion(prompt, self.model)
        try:
            return json.loads(response)
        except:
            return {
                "rewritten_query": query,
                "search_keywords": [query],
                "search_intent": "信息查询",
                "suggested_sources": ["官方网站", "旅游网站"]
            }
```

##### 3、生成搜索策略

```python
def generate_search_strategy(self, query, search_type="general"):
        """生成搜索策略"""
        current_date = datetime.now().strftime("%Y年%m月%d日")
        instruction = f"""
你是一个搜索策略专家。请为用户的查询制定详细的搜索策略。

当前日期：{current_date}

搜索策略包括：
1. 主要搜索词 - 核心关键词
2. 扩展搜索词 - 相关词汇和同义词
3. 搜索网站 - 推荐的搜索平台
4. 时间范围 - 具体的搜索时间范围

请返回JSON格式：
{{
    "primary_keywords": ["主要关键词"],
    "extended_keywords": ["扩展关键词"],
    "search_platforms": ["搜索平台"],
    "time_range": "具体的时间范围"
}}
"""

        prompt = f"""
### 指令 ###
{instruction}

### 用户查询 ###
{query}

### 搜索类型 ###
{search_type}

### 搜索策略 ###
"""

        response = get_completion(prompt, self.model)
        try:
            return json.loads(response)
        except:
            return {
                "primary_keywords": [query],
                "extended_keywords": [],
                "search_platforms": ["百度", "谷歌"],
                "time_range": "最近一周"
            }
```

# RAG高效召回方法

前面我们知道了RAG的召回是根据向量相似度进行召回，但是有时候向量相似度召回的并不一定最好的。

比如说提问：张三的女儿年龄是多少？现在有两个chunk，分别是：

```css
# chunk1
张三的女儿叫AAA
# chunk2
AAA今年14岁
```

这样通过相似度召回可能会找回chunk1，就可能导致回答效果不好了。所以我们需要采取一些方法提高RAG的召回效率。

### 1、改进检索算法

##### 1.1、知识图谱

利用知识图谱中的语义信息和实体关系，增强对查询和文档的理解，提升召回的相关性。比如GraphRAG。

**CASE1：GraphRAG使用**

GraphRAG是一种结构化、分层的检索生成（RAG）方法，而不是使用纯文本片段的语义检索方法。即基于图谱结构进行推理，从而实现更聪明的检索。

> 原始文档中提取知识图谱 → 构建社区层级（个体之间的关系社区）→ 为这些层级生成摘要

### 2、引入重排序（Reranking）

##### 2.1、重排序模型

对召回的chunk进行重新排序，提升问题和文档的相关性。常见的重排序模型有`BGE-Rerank`和`Cohere Rerank`。

重排序Rerank主要用于初步检索结果的排序，提高最终输出的相关性和准确性。

重排序和Embedding是有区别的，Embedding是通过计算向量相似度，而重排序可以理解成监督学习（通过大量样本进行监督学习生成的模型）

比如先从100万chunk中召回100个chunk，然后通过Rerank模型让提问和这100个chunk进行语义重排序，取出重排序后的Top5再对LLM进行提问。

**CASE1：BGE-Rerank使用：**

先下载BGE-Rerank模型：

```python
from modelscope import snapshot_download
model_dir = snapshot_download('BAAI/bge-reranker-large', cache_dir='/root/autodl-tmp/models')
```

再使用BGE-Rerank：

```python
import torch
from transformers import AutoModelForSequenceClassification, AutoTokenizer

tokenizer = AutoTokenizer.from_pretrained('BAAI/bge-reranker-large')
model = AutoModelForSequenceClassification.from_pretrained('BAAI/bge-reranker-large')
model.eval()

pairs = [['what is panda?', 'The giant panda is a bear species endemic to China.']]
inputs = tokenizer(pairs, padding=True, truncation=True, return_tensors='pt')
scores = model(**inputs).logits.view(-1).float()
print(scores)
```

执行结果：

```shell
4.9538
# 在BGE-Rerank模型中，相关性分数scores是一个未归一化的对数几率（logits）值，范围没有固定的上
# 限或下限（不像某些模型限制在0-1）。不过BGE-Rerank的分数通常落在以下范围：
# 高相关性： 3.0~10.0
# 中等相关性：0.0~3.0
# 低相关性/不相关：负数（如-5.0以下）

# 可以看出两者的相关性属于高相关性
```

##### 2.2、混合检索

结合向量检索和关键词检索的优势，通过重排序模型对结果进行归一化处理，提升召回质量。

### 3、优化查询拓展

##### 3.1、相似语义改写

使用大模型将用户的query改写成多个语义相近的查询，从而提升召回多样性。通过LangChain的`multiQueryRetriever`可以实现Query的改写。

##### 3.2、双向改写

将查询改写成文档（Query2Doc）或为文档生成查询（Doc2Query），缓解短文本向量化效果差的问题。

**Query2Doc：** 将查询改成文档，通过先对Query进行回答，然后通过预先的回答去chunks中召回

**Doc2Query：** 为文档生成关联查询，对Doc预先设定有可能出现的Query，从而提高召回效果。

原理就是增加更多可能的抓手，提高召回正确率

### 4、索引拓展

##### 4.1、离散索引拓展

使用关键词抽取、实体识别等技术生成离散索引，与向量检索互补，提升召回准确性。

比如一段chunk如下：

```css
本文介绍了深度学习模型训练中的优化技巧，包括：
1. 使用 AdamW 优化器替代传统的 SGD。
2. 采用混合精度训练，减少显存占用。
3. 使用分布式训练技术加速大规模模型的训练。
```

通过关键词提取技术可以提取如下的关键词：

```css
["深度学习", "模型训练", "优化技巧", "AdamW", "混合精度训练", "分布式训练"]
```

当用户查询“如何优化深度学习模型训练？”时，离散索引中的关键词能够快速匹配到相关文档。

##### 4.2、连续索引扩展

结合多种向量模型（如OpenAI的Ada、智源的BGE）进行多路召回，取长补短。

##### 4.3、混合索引召回

将BM25等离散索引与向量索引结合，通过Ensemble Retriever实现混合召回，提升召回多样性。

### 5、Small-to-Big索引策略

Small-to-Big是一种高效的检索方法，特别适用于处理长文档或多文档场景。核心思想是通过小规模内容（如摘要、关键句或段落）建立索引，并链接到大规模内容主体中。这种策略的优势在于能够快速定位相关的小规模内容，并通过链接获取更详细的上下文信息，从而提高检索效率和答案的逻辑连贯性。

比如一篇很长的文档，可以对其进行提取摘要，当用户输入Query后，先在摘要中检索，摘要又映射到长doc，召回长文档作为上下文对LLM进行提问。

# 知识库处理方案

当知识库本身存在缺陷或者需要加强知识库检索效果时，我们需要对知识库进行处理，以达到升级知识库的效果。

### 1、知识库问题生成和检索优化

当用户提问和知识切片的相似度不高时，我们可以通过LLM给每个切片生成可能的问题，通过问题和问题的匹配来提高检索准确性。

##### 1.1、自动生成多样化问题

通过LLM为每个切片生成多种类型、不同难度的问题。

```python
def generate_questions_for_chunk(self, knowledge_chunk, num_questions = 5):
        """为单个知识切片生成多样化问题"""
        instruction = """
你是一个专业的问答系统专家。给定的知识内容能回答哪些多样化的问题，这些问题可以：
1. 使用不同的问法（直接问、间接问、对比问等）
2. 避免重复和相似的问题
3. 确保问题不超出知识内容范围

请返回JSON格式：
{
    "questions": [
        {
            "question": "问题内容",
            "question_type": "问题类型（直接问/间接问/对比问/条件问等）",
            "difficulty": "难度等级（简单/中等/困难）"
        }
    ]
}
"""
        prompt = f"""
### 指令 ###
{instruction}

### 知识内容 ###
{knowledge_chunk}

### 生成问题数量 ###
{num_questions}

### 生成结果 ###
"""
        response = get_completion(prompt, model=self.model)
        # 处理AI响应，移除markdown代码块格式
        response = preprocess_json_response(response)

        try:
            result = json.loads(response)
            return  result.get("questions", [])
        except json.JSONDecodeError:
            print("JSON 解析错误，原始响应如下：")
            print(response)
            return [{"question": f"关于{knowledge_chunk[:50]}...的问题", "question_type": "直接问", "keywords": [], "difficulty": "中等"}]

def generate_diverse_questions(self, knowledge_chunk, num_questions=8):
        """生成更多样化的问题（更丰富）"""
        instruction = """
你是一个专业的问答系统专家。请为给定的知识内容生成高度多样化的问题，确保：
1. 问题类型多样化：直接问、间接问、对比问、条件问、假设问、推理问等
2. 表达方式多样化：使用不同的句式、词汇、语气
3. 难度层次多样化：简单、中等、困难的问题都要有
4. 角度多样化：从不同角度和维度提问
5. 确保问题不超出知识内容范围

请返回JSON格式：
{
    "questions": [
        {
            "question": "问题内容",
            "question_type": "问题类型",
            "difficulty": "难度等级",
            "perspective": "提问角度",
            "is_answerable": "给出的知识能否回答该问题",
            "answer": "基于该知识的回答"
        }
    ]
}
"""

        prompt = f"""
### 指令 ###
{instruction}

### 知识内容 ###
{knowledge_chunk}

### 生成问题数量 ###
{num_questions}

### 生成结果 ###
"""

        response = get_completion(prompt, self.model)

        # 预处理响应，移除markdown代码块格式
        response = preprocess_json_response(response)

        try:
            result = json.loads(response)
            return result.get('questions', [])
        except json.JSONDecodeError as e:
            print(f"多样化问题生成JSON解析失败: {e}")
            print(f"AI返回内容: {response[:200]}...")
            return []
```

##### 2、检索评估

针对生成多样化问题后的和原切片检索评估。

##### 完整案例：

```python
# 导入依赖库
import os
import json
import numpy as np
from openai import OpenAI
import pandas as pd
from datetime import datetime
from rank_bm25 import BM25Okapi
import jieba
import re

# 从环境变量中获取 API Key
DASHSCOPE_API_KEY = "xxxxxxxxxxxxxxxxxxxxxxxxxx"

# 初始化百炼兼容的 OpenAI 客户端
client = OpenAI(
    api_key=DASHSCOPE_API_KEY,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# 预处理AI响应中的JSON格式
def preprocess_json_response(response):
    """预处理AI响应，移除markdown代码块格式"""
    if not response:
        return ""

    # 移除markdown代码块格式
    if response.startswith('```json'):
        response = response[7:]  # 移除 ```json
    elif response.startswith('```'):
        response = response[3:]  # 移除 ```

    if response.endswith('```'):
        response = response[:-3]  # 移除结尾的 ```

    return response.strip()  # 移除首尾空白

# 基于 prompt 生成文本
def get_completion(prompt, model="qwen-turbo-latest"):
    messages = [{"role": "user", "content": prompt}]
    response = client.chat.completions.create(
        model=model,
        messages=messages,
        temperature=0.7,
    )
    return response.choices[0].message.content

# 文本预处理和分词
def preprocess_text(text):
    """文本预处理和分词"""
    if not text:
        return []

    # 移除标点符号和特殊字符
    text = re.sub(r'[^\w\s]', '', text)

    # 使用jieba分词
    words = jieba.lcut(text)

    # 过滤停用词和短词
    stop_words = {'的', '了', '在', '是', '我', '有', '和', '就', '不', '人', '都', '一', '一个', '上', '也', '很', '到', '说', '要', '去', '你', '会', '着', '没有', '看', '好', '自己', '这'}
    words = [word for word in words if len(word) > 1 and word not in stop_words]

    return words

class KnowledgeBaseOptimizer:
    def __init__(self, model="qwen-turbo-latest"):
        self.model = model
        self.knowledge_base = []
        self.content_bm25 = None
        self.question_bm25 = None
        self.content_documents = []
        self.question_documents = []
        self.content_metadata = []
        self.question_metadata = []

    def generate_questions_for_chunk(self, knowledge_chunk, num_questions=5):
        """为单个知识切片生成多样化问题"""
        instruction = """
你是一个专业的问答系统专家。给定的知识内容能回答哪些多样化的问题，这些问题可以：
1. 使用不同的问法（直接问、间接问、对比问等）
2. 避免重复和相似的问题
3. 确保问题不超出知识内容范围

请返回JSON格式：
{
    "questions": [
        {
            "question": "问题内容",
            "question_type": "问题类型（直接问/间接问/对比问/条件问等）",
            "difficulty": "难度等级（简单/中等/困难）"
        }
    ]
}
"""

        prompt = f"""
### 指令 ###
{instruction}

### 知识内容 ###
{knowledge_chunk}

### 生成问题数量 ###
{num_questions}

### 生成结果 ###
"""

        response = get_completion(prompt, self.model)

        # 预处理响应，移除markdown代码块格式
        response = preprocess_json_response(response)

        try:
            result = json.loads(response)
            return result.get('questions', [])
        except json.JSONDecodeError as e:
            print(f"JSON解析失败: {e}")
            print(f"AI返回内容: {response[:50]}...")
            # 如果JSON解析失败，返回简单的问题列表
            return [{"question": f"关于{knowledge_chunk[:50]}...的问题", "question_type": "直接问", "keywords": [], "difficulty": "中等"}]

    def build_knowledge_index(self, knowledge_base):
        """构建知识库的BM25索引（包括原文和问题）"""
        print("正在构建知识库索引...")

        self.knowledge_base = knowledge_base
        content_documents = []
        question_documents = []
        content_metadata = []
        question_metadata = []

        for i, chunk in enumerate(knowledge_base):
            # 获取知识切片的内容
            text = chunk.get('content', '')
            if not text.strip():
                continue

            # 原文文档
            content_words = preprocess_text(text)
            if content_words:
                content_documents.append(content_words)
                content_metadata.append({
                    "id": chunk.get('id', f"chunk_{i}"),
                    "content": text,
                    "category": chunk.get('category', ''),
                    "chunk": chunk,
                    "type": "content"
                })

            # 问题文档（如果存在生成的问题）
            if 'generated_questions' in chunk and chunk['generated_questions']:
                for j, question_data in enumerate(chunk['generated_questions']):
                    question = question_data.get('question', '')
                    if question.strip():
                        # 拼接全文和问题，保持上下文
                        combined_text = f"内容：{text} 问题：{question}"
                        question_words = preprocess_text(combined_text)

                        if question_words:
                            question_documents.append(question_words)
                            question_metadata.append({
                                "id": f"{chunk.get('id', f'chunk_{i}')}_q{j}",
                                "content": question,
                                "combined_content": combined_text,
                                "category": chunk.get('category', ''),
                                "chunk": chunk,
                                "type": "question",
                                "question_data": question_data
                            })

        # 创建BM25索引
        if content_documents:
            self.content_bm25 = BM25Okapi(content_documents)
            self.content_documents = content_documents
            self.content_metadata = content_metadata
            print(f"原文索引构建完成，共索引 {len(content_documents)} 个知识切片")

        if question_documents:
            self.question_bm25 = BM25Okapi(question_documents)
            self.question_documents = question_documents
            self.question_metadata = question_metadata
            print(f"问题索引构建完成，共索引 {len(question_documents)} 个问题")

        if not content_documents and not question_documents:
            print("没有有效的内容可以索引")

    def search_similar_chunks(self, query, k=3, search_type="content"):
        """使用BM25搜索相似的内容（原文或问题）"""
        if search_type == "content":
            if not self.content_bm25:
                return []
            bm25 = self.content_bm25
            metadata_store = self.content_metadata
        elif search_type == "question":
            if not self.question_bm25:
                return []
            bm25 = self.question_bm25
            print('question_bm25=', bm25)
            metadata_store = self.question_metadata
        else:
            return []

        try:
            # 预处理查询
            query_words = preprocess_text(query)
            if not query_words:
                return []

            # 搜索最相似的k个内容
            scores = bm25.get_scores(query_words)

            # 获取top-k结果
            top_indices = np.argsort(scores)[::-1][:k]

            results = []
            for idx in top_indices:
                if scores[idx] > 0:  # 只返回有相关性的结果
                    metadata = metadata_store[idx]
                    # 将BM25分数转换为0-1范围的相似度
                    similarity = min(1.0, scores[idx] / 10.0)  # 归一化
                    results.append({
                        "metadata": metadata,
                        "score": scores[idx],
                        "similarity": similarity
                    })

            return results

        except Exception as e:
            print(f"搜索失败: {e}")
            return []

    def calculate_similarity(self, query, knowledge_chunk):
        """计算查询与知识切片的相似度（使用BM25）"""
        try:
            query_words = preprocess_text(query)
            chunk_words = preprocess_text(knowledge_chunk)

            if not query_words or not chunk_words:
                return 0.0

            # 创建临时BM25索引
            temp_bm25 = BM25Okapi([chunk_words])
            scores = temp_bm25.get_scores(query_words)

            # 返回最高分数并归一化
            max_score = max(scores) if scores else 0.0
            return min(1.0, max_score / 10.0)

        except Exception as e:
            print(f"相似度计算失败: {e}")
            return 0.0

    def calculate_question_similarity(self, user_query, generated_questions):
        """计算用户查询与生成问题的相似度"""
        similarities = []
        for question_data in generated_questions:
            question = question_data['question']
            similarity = self.calculate_similarity(user_query, question)
            similarities.append(similarity)
        return max(similarities) if similarities else 0.0

    def evaluate_retrieval_methods(self, knowledge_base, test_queries):
        """评估两种检索方法的准确度"""
        # 首先构建知识库索引（包括原文和问题）
        self.build_knowledge_index(knowledge_base)

        results = {
            'content_similarity': [],
            'question_similarity': [],
            'improvement': [],
            'content_scores': [],
            'question_scores': [],
            'query_details': []
        }

        for i, query_info in enumerate(test_queries):
            user_query = query_info['query']
            correct_chunk = query_info['correct_chunk']

            # 方法1：BM25原文检索
            content_results = self.search_similar_chunks(user_query, k=1, search_type="content")
            content_correct = False
            content_score = 0.0
            content_chunk_id = None
            if content_results:
                best_match = content_results[0]['metadata']['chunk']
                content_correct = best_match['content'] == correct_chunk
                content_score = content_results[0]['similarity']
                content_chunk_id = best_match['id']

            # 方法2：BM25问题检索
            question_results = self.search_similar_chunks(user_query, k=1, search_type="question")
            question_correct = False
            question_score = 0.0
            question_chunk_id = None
            if question_results:
                best_match = question_results[0]['metadata']['chunk']
                question_correct = best_match['content'] == correct_chunk
                question_score = question_results[0]['similarity']
                question_chunk_id = best_match['id']

            results['content_similarity'].append(content_correct)
            results['question_similarity'].append(question_correct)
            results['improvement'].append(question_correct and not content_correct)
            results['content_scores'].append(content_score)
            results['question_scores'].append(question_score)

            # 记录查询详情
            results['query_details'].append({
                'query': user_query,
                'content_score': content_score,
                'question_score': question_score,
                'content_correct': content_correct,
                'question_correct': question_correct,
                'score_diff': question_score - content_score,
                'content_chunk_id': content_chunk_id,
                'question_chunk_id': question_chunk_id
            })

        return results

    def generate_diverse_questions(self, knowledge_chunk, num_questions=8):
        """生成更多样化的问题（更丰富）"""
        instruction = """
你是一个专业的问答系统专家。请为给定的知识内容生成高度多样化的问题，确保：
1. 问题类型多样化：直接问、间接问、对比问、条件问、假设问、推理问等
2. 表达方式多样化：使用不同的句式、词汇、语气
3. 难度层次多样化：简单、中等、困难的问题都要有
4. 角度多样化：从不同角度和维度提问
5. 确保问题不超出知识内容范围

请返回JSON格式：
{
    "questions": [
        {
            "question": "问题内容",
            "question_type": "问题类型",
            "difficulty": "难度等级",
            "perspective": "提问角度",
            "is_answerable": "给出的知识能否回答该问题",
            "answer": "基于该知识的回答"
        }
    ]
}
"""

        prompt = f"""
### 指令 ###
{instruction}

### 知识内容 ###
{knowledge_chunk}

### 生成问题数量 ###
{num_questions}

### 生成结果 ###
"""

        response = get_completion(prompt, self.model)

        # 预处理响应，移除markdown代码块格式
        response = preprocess_json_response(response)

        try:
            result = json.loads(response)
            return result.get('questions', [])
        except json.JSONDecodeError as e:
            print(f"多样化问题生成JSON解析失败: {e}")
            print(f"AI返回内容: {response[:200]}...")
            return []

def main():
    # 初始化知识库优化器
    optimizer = KnowledgeBaseOptimizer()

    print("=== 知识库问题生成与检索优化示例（BM25版本）- 迪士尼主题乐园 ===\n")

    # 示例知识库
    knowledge_base = [
        {
            "id": "kb_001",
            "content": "上海迪士尼乐园位于上海市浦东新区，是中国大陆首座迪士尼主题乐园，于2016年6月16日开园。乐园占地面积390公顷，包含七大主题园区：米奇大街、奇想花园、探险岛、宝藏湾、明日世界、梦幻世界和迪士尼小镇。",
            "category": "基本信息"
        },
        {
            "id": "kb_002", 
            "content": "上海迪士尼乐园的门票价格根据季节和日期有所不同。平日成人票价为399元，周末和节假日为499元。儿童票（1.0-1.4米）平日为299元，周末和节假日为374元。1.0米以下儿童免费入园。",
            "category": "价格信息"
        },
        {
            "id": "kb_003",
            "content": "上海迪士尼乐园的营业时间通常为上午8:00至晚上8:00，但具体时间会根据季节和特殊活动进行调整。建议游客在出发前查看官方网站或APP获取最新的营业时间信息。",
            "category": "营业信息"
        },
        {
            "id": "kb_004",
            "content": "从上海市区到上海迪士尼乐园有多种交通方式：1. 地铁11号线迪士尼站下车；2. 乘坐迪士尼专线巴士；3. 打车约40-60分钟；4. 自驾车可停在乐园停车场，停车费为100元/天。",
            "category": "交通信息"
        },
        {
            "id": "kb_005",
            "content": "上海迪士尼乐园的特色项目包括：创极速光轮（明日世界）、七个小矮人矿山车（梦幻世界）、加勒比海盗：战争之潮（宝藏湾）、翱翔·飞越地平线（探险岛）等。这些项目都有不同的身高和年龄限制。",
            "category": "游乐项目"
        },
        {
            "id": "kb_006",
            "content": "上海迪士尼乐园提供多种餐饮选择，包括米奇大街的皇家宴会厅、奇想花园的漫月轩、宝藏湾的巴波萨烧烤等。园内餐厅价格相对较高，人均消费约150-300元。建议游客可以携带密封包装的零食和水入园。",
            "category": "餐饮信息"
        },
        {
            "id": "kb_007",
            "content": "上海迪士尼乐园的购物体验非常丰富，每个主题园区都有特色商店。米奇大街的M大街购物廊是最大的综合商店，销售各种迪士尼周边商品。建议游客在离园前购买纪念品，避免携带不便。",
            "category": "购物信息"
        },
        {
            "id": "kb_008",
            "content": "上海迪士尼乐园提供多种服务设施，包括婴儿车租赁（50元/天）、轮椅租赁（免费）、储物柜（60元/天）、充电宝租赁等。园内设有多个医疗点和失物招领处，为游客提供便利服务。",
            "category": "服务设施"
        }
    ]

    # 示例1: 为知识切片生成问题
    print("示例1: 为知识切片生成多样化问题")
    test_chunk = knowledge_base[0]['content']
    print(f"知识内容: {test_chunk}")

    questions = optimizer.generate_questions_for_chunk(test_chunk, num_questions=5)
    print(f"\n生成的5个问题:")
    for i, q in enumerate(questions, 1):
        print(f"  {i}. {q['question']} (类型: {q['question_type']}, 难度: {q['difficulty']})")

    print("\n" + "="*60 + "\n")

    # 示例2: 生成更多样化的问题
    print("示例2: 生成更多样化的问题（8个）")
    diverse_questions = optimizer.generate_diverse_questions(test_chunk, num_questions=8)
    print(f"\n生成的8个多样化问题:")
    for i, q in enumerate(diverse_questions, 1):
        print(f"  {i}. {q['question']}")
        print(f"     类型: {q['question_type']}, 难度: {q['difficulty']}, 角度: {q['perspective']}, 能否回答: {q['is_answerable']}, 回答的答案：{q['answer']}")

    print("\n" + "="*60 + "\n")

    # 示例3: 评估检索方法
    print("示例3: 评估两种检索方法的准确度")

    # 测试查询 - 设计更有挑战性的问题
    test_queries = [
        {
            "query": "如果我想体验最刺激的过山车，应该去哪个区域？",
            "correct_chunk": knowledge_base[4]['content']
        },
        {
            "query": "什么时间去人比较少？",
            "correct_chunk": knowledge_base[2]['content']
        },
        {
            "query": "可以带食物进去吗？",
            "correct_chunk": knowledge_base[5]['content']
        }
    ]

    # 为知识库生成问题
    print('正在为知识库生成问题...')
    for chunk in knowledge_base:
        chunk['generated_questions'] = optimizer.generate_questions_for_chunk(chunk['content'])
        #print("chunk['generated_questions']=", chunk['generated_questions'])
    print('为知识库生成问题完毕')

    # 评估检索方法
    results = optimizer.evaluate_retrieval_methods(knowledge_base, test_queries)

    print(f"测试查询数量: {len(test_queries)}")
    print(f"BM25原文检索准确率: {sum(results['content_similarity'])/len(results['content_similarity'])*100:.1f}%")
    print(f"BM25问题检索准确率: {sum(results['question_similarity'])/len(results['question_similarity'])*100:.1f}%")
    print(f"问题检索改进的查询数量: {sum(results['improvement'])}")

    # 详细分析
    print(f"\n=== 详细分析 ===")

    # 按相似度分数差异排序
    sorted_details = sorted(results['query_details'], key=lambda x: x['score_diff'], reverse=True)

    print(f"\n问题检索方法表现更好的查询（按分数差异排序）:")
    for i, detail in enumerate(sorted_details[:5], 1):
        if detail['score_diff'] > 0:
            print(f"  {i}. 查询: {detail['query']}")
            print(f"     原文检索分数: {detail['content_score']:.3f}")
            print(f"     问题检索分数: {detail['question_score']:.3f}")
            print(f"     分数差异: +{detail['score_diff']:.3f}")
            print(f"     原文检索: {'✓' if detail['content_correct'] else '✗'}")
            print(f"     问题检索: {'✓' if detail['question_correct'] else '✗'}")

    print(f"\n原文检索方法表现更好的查询:")
    for i, detail in enumerate(sorted_details[-5:], 1):
        if detail['score_diff'] < 0:
            print(f"  {i}. 查询: {detail['query']}")
            print(f"     原文检索分数: {detail['content_score']:.3f}")
            print(f"     问题检索分数: {detail['question_score']:.3f}")
            print(f"     分数差异: {detail['score_diff']:.3f}")
            print(f"     原文检索: {'✓' if detail['content_correct'] else '✗'}")
            print(f"     问题检索: {'✓' if detail['question_correct'] else '✗'}")


if __name__ == "__main__":
    main()
```

运行结果：

```shell
=== 知识库问题生成与检索优化示例（BM25版本）- 迪士尼主题乐园 ===

示例1: 为知识切片生成多样化问题
知识内容: 上海迪士尼乐园位于上海市浦东新区，是中国大陆首座迪士尼主题乐园，于2016年6月16日开园。乐园占地面积390公顷，包含七大主题园区：米奇大街、奇想花园、探险岛、宝藏湾、明日世界、梦幻世界和迪士尼小镇。

生成的5个问题:
  1. 上海迪士尼乐园是什么时候开园的？ (类型: 直接问, 难度: 简单)
  2. 中国大陆第一座迪士尼主题乐园在哪里？ (类型: 间接问, 难度: 简单)
  3. 上海迪士尼乐园和别的迪士尼乐园相比有什么特别之处？ (类型: 对比问, 难度: 中等)
  4. 如果想去上海迪士尼乐园，它位于哪个区？ (类型: 条件问, 难度: 简单)
  5. 上海迪士尼乐园包含哪些主题园区？ (类型: 直接问, 难度: 中等)

============================================================

示例2: 生成更多样化的问题（8个）

生成的8个多样化问题:
  1. 上海迪士尼乐园是在哪一年开园的？
     类型: 直接问, 难度: 简单, 角度: 时间维度, 能否回答: True, 回答的答案：2016年
  2. 如果中国没有迪士尼乐园，上海迪士尼会存在吗？
     类型: 假设问, 难度: 中等, 角度: 因果关系, 能否回答: True, 回答的答案：不会，因为上海迪士尼是中国大陆首座迪士尼主题乐园，其存在依赖于中国有迪士尼乐园这一前提。
  3. 上海迪士尼和美国其他迪士尼乐园相比，在主题园区数量上有什么不同？
     类型: 对比问, 难度: 中等, 角度: 空间比较, 能否回答: True, 回答的答案：知识中未提供其他国家迪士尼乐园的主题园区数量，因此无法直接对比。但明确指出上海迪士尼包含七大主题园区。
  4. 为什么说上海迪士尼是‘中国大陆首座’迪士尼主题乐园？
     类型: 推理问, 难度: 困难, 角度: 逻辑推理, 能否回答: True, 回答的答案：因为它是第一个在中国大陆建成并运营的迪士尼主题乐园，之前中国没有其他迪士尼乐园。
  5. 你能否根据面积信息推断出上海迪士尼的规模是否超过一般城市公园？
     类型: 推理问, 难度: 中等, 角度: 规模判断, 能否回答: True, 回答的答案：可以，390公顷相当于约585个标准足球场大小，通常远大于大多数城市公园（如北京奥林匹克森林公园约686公顷），说明其规模宏大。
  6. 假如你想去上海迪士尼玩，应该关注哪些区域？
     类型: 条件问, 难度: 简单, 角度: 实用建议, 能否回答: True, 回答的答案：应关注七大主题园区：米奇大街、奇想花园、探险岛、宝藏湾、明日世界、梦幻世界和迪士尼小镇。
  7. 上海迪士尼乐园的占地面积是多少公顷？
     类型: 直接问, 难度: 简单, 角度: 数值记忆, 能否回答: True, 回答的答案：390公顷
  8. 迪士尼小镇是不是上海迪士尼乐园的一部分？
     类型: 间接问, 难度: 简单, 角度: 结构认知, 能否回答: True, 回答的答案：是的，迪士尼小镇是上海迪士尼乐园的组成部分之一。

============================================================

示例3: 评估两种检索方法的准确度
正在为知识库生成问题...
为知识库生成问题完毕
正在构建知识库索引...
Building prefix dict from the default dictionary ...
Dumping model to file cache /var/folders/n9/dw75j0jn0z72hs8xlytdky9c0000gn/T/jieba.cache
Loading model cost 0.701 seconds.
Prefix dict has been built successfully.
原文索引构建完成，共索引 8 个知识切片
问题索引构建完成，共索引 40 个问题
question_bm25= <rank_bm25.BM25Okapi object at 0x11e260f10>
question_bm25= <rank_bm25.BM25Okapi object at 0x11e260f10>
question_bm25= <rank_bm25.BM25Okapi object at 0x11e260f10>
测试查询数量: 3
BM25原文检索准确率: 66.7%
BM25问题检索准确率: 100.0%
问题检索改进的查询数量: 1

=== 详细分析 ===

问题检索方法表现更好的查询（按分数差异排序）:
  1. 查询: 可以带食物进去吗？
     原文检索分数: 0.153
     问题检索分数: 0.556
     分数差异: +0.403
     原文检索: ✓
     问题检索: ✓
  2. 查询: 如果我想体验最刺激的过山车，应该去哪个区域？
     原文检索分数: 0.155
     问题检索分数: 0.476
     分数差异: +0.320
     原文检索: ✗
     问题检索: ✓
  3. 查询: 什么时间去人比较少？
     原文检索分数: 0.168
     问题检索分数: 0.297
     分数差异: +0.130
     原文检索: ✓
     问题检索: ✓

原文检索方法表现更好的查询:
```

### 2、对话知识沉淀

产品上线后每天有大量的对话，我们可以从大量对话信息中提取和沉淀有价值的知识，持续丰富知识库。

##### 2.1、对对话信息进行分类

```python
class ConversationKnowledgeExtractor:
    def __init__(self, model="qwen-turbo-latest"):
        self.model = model
        self.extracted_knowledge = []
        self.knowledge_frequency = Counter()

    def extract_knowledge_from_conversation(self, conversation):
        """从单次对话中提取知识"""
        instruction = """
你是一个专业的知识提取专家。请从给定的对话中提取有价值的知识点，包括：
1. 事实性信息（地点、时间、价格、规则等）
2. 用户需求和偏好
3. 常见问题和解答
4. 操作流程和步骤
5. 注意事项和提醒

请返回JSON格式：
{
    "extracted_knowledge": [
        {
            "knowledge_type": "知识类型（事实/需求/问题/流程/注意）",
            "content": "知识内容",
            "confidence": "置信度(0-1)",
            "source": "来源（用户/AI/对话）",
            "keywords": ["关键词1", "关键词2"],
            "category": "分类"
        }
    ],
    "conversation_summary": "对话摘要",
    "user_intent": "用户意图"
}
"""

        prompt = f"""
### 指令 ###
{instruction}

### 对话内容 ###
{conversation}

### 提取结果 ###
"""

        response = get_completion(prompt, self.model)

        # 预处理响应，移除markdown代码块格式
        response = preprocess_json_response(response)

        try:
            result = json.loads(response)
            return result
        except json.JSONDecodeError as e:
            print(f"对话知识提取JSON解析失败: {e}")
            print(f"AI返回内容: {response[:200]}...")
            return {
                "extracted_knowledge": [],
                "conversation_summary": "无法解析对话",
                "user_intent": "未知"
            }

    def batch_extract_knowledge(self, conversations):
        """批量提取知识"""
        all_knowledge = []

        for i, conversation in enumerate(conversations):
            print(f"正在处理对话 {i+1}/{len(conversations)}...")

            result = self.extract_knowledge_from_conversation(conversation)
            all_knowledge.extend(result.get('extracted_knowledge', []))

            # 更新频率统计
            for knowledge in result.get('extracted_knowledge', []):
                key = f"{knowledge['knowledge_type']}:{knowledge['content'][:50]}"
                self.knowledge_frequency[key] += 1

        return all_knowledge
# .....
```

##### 2.2、过滤掉不是知识的内容

根据实际情况根据LLM整理出来的知识类型来做具体的过滤。

```python
# 过滤掉需求和问题类型的知识，因为它们是临时的、个性化的
filtered_knowledge = [
      knowledge for knowledge in knowledge_list 
      if knowledge.get('knowledge_type') not in ['需求', '问题']
]
```

##### 2.3、对知识点进行合并，形成新的知识

使用LLM进行智能合并，以下是LLM的合并流程：

```python
# 按知识类型分组
knowledge_by_type = {}
for knowledge in filtered_knowledge:
    knowledge_type = knowledge.get('knowledge_type', '其他')
    if knowledge_type not in knowledge_by_type:
        knowledge_by_type[knowledge_type] = []
    knowledge_by_type[knowledge_type].append(knowledge)

merged_knowledge = []

# 对每个知识类型分别进行LLM合并
for knowledge_type, knowledge_group in knowledge_by_type.items():
    if len(knowledge_group) == 1:
        # 只有一个知识点，直接添加
        merged_knowledge.append(knowledge_group[0])
    else:
        # 多个知识点，使用LLM合并
        merged = self.merge_knowledge_with_llm(knowledge_group, knowledge_type)
        merged_knowledge.append(merged)
```

##### 完整案例

```python
# 对话知识提取与沉淀
# 导入依赖库
import dashscope
import os
import json
from datetime import datetime
from collections import Counter

# 从环境变量中获取 API Key
dashscope.api_key = "xxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# 预处理AI响应中的JSON格式
def preprocess_json_response(response):
    """预处理AI响应，移除markdown代码块格式"""
    if not response:
        return ""

    # 移除markdown代码块格式
    if response.startswith('```json'):
        response = response[7:]  # 移除 ```json
    elif response.startswith('```'):
        response = response[3:]  # 移除 ```

    if response.endswith('```'):
        response = response[:-3]  # 移除结尾的 ```

    return response.strip()  # 移除首尾空白

# 基于 prompt 生成文本
def get_completion(prompt, model="qwen-turbo-latest"):
    messages = [{"role": "user", "content": prompt}]
    response = dashscope.Generation.call(
        model=model,
        messages=messages,
        result_format='message',
        temperature=0.3,
    )
    return response.output.choices[0].message.content

class ConversationKnowledgeExtractor:
    def __init__(self, model="qwen-turbo-latest"):
        self.model = model
        self.extracted_knowledge = []
        self.knowledge_frequency = Counter()

    def extract_knowledge_from_conversation(self, conversation):
        """从单次对话中提取知识"""
        instruction = """
你是一个专业的知识提取专家。请从给定的对话中提取有价值的知识点，包括：
1. 事实性信息（地点、时间、价格、规则等）
2. 用户需求和偏好
3. 常见问题和解答
4. 操作流程和步骤
5. 注意事项和提醒

请返回JSON格式：
{
    "extracted_knowledge": [
        {
            "knowledge_type": "知识类型（事实/需求/问题/流程/注意）",
            "content": "知识内容",
            "confidence": "置信度(0-1)",
            "source": "来源（用户/AI/对话）",
            "keywords": ["关键词1", "关键词2"],
            "category": "分类"
        }
    ],
    "conversation_summary": "对话摘要",
    "user_intent": "用户意图"
}
"""

        prompt = f"""
### 指令 ###
{instruction}

### 对话内容 ###
{conversation}

### 提取结果 ###
"""

        response = get_completion(prompt, self.model)

        # 预处理响应，移除markdown代码块格式
        response = preprocess_json_response(response)

        try:
            result = json.loads(response)
            return result
        except json.JSONDecodeError as e:
            print(f"对话知识提取JSON解析失败: {e}")
            print(f"AI返回内容: {response[:200]}...")
            return {
                "extracted_knowledge": [],
                "conversation_summary": "无法解析对话",
                "user_intent": "未知"
            }

    def batch_extract_knowledge(self, conversations):
        """批量提取知识"""
        all_knowledge = []

        for i, conversation in enumerate(conversations):
            print(f"正在处理对话 {i+1}/{len(conversations)}...")

            result = self.extract_knowledge_from_conversation(conversation)
            all_knowledge.extend(result.get('extracted_knowledge', []))

            # 更新频率统计
            for knowledge in result.get('extracted_knowledge', []):
                key = f"{knowledge['knowledge_type']}:{knowledge['content'][:50]}"
                self.knowledge_frequency[key] += 1

        return all_knowledge

    def merge_similar_knowledge(self, knowledge_list):
        """使用LLM合并相似的知识点，过滤掉需求和问题类型"""
        # 过滤掉需求和问题类型的知识，因为它们是临时的、个性化的
        filtered_knowledge = [
            knowledge for knowledge in knowledge_list 
            if knowledge.get('knowledge_type') not in ['需求', '问题']
        ]

        print(f"过滤前知识点数量: {len(knowledge_list)}")
        print(f"过滤后知识点数量: {len(filtered_knowledge)}")
        print(f"过滤掉的'需求'和'问题'类型知识点: {len(knowledge_list) - len(filtered_knowledge)}")

        # 按知识类型分组
        knowledge_by_type = {}
        for knowledge in filtered_knowledge:
            knowledge_type = knowledge.get('knowledge_type', '其他')
            if knowledge_type not in knowledge_by_type:
                knowledge_by_type[knowledge_type] = []
            knowledge_by_type[knowledge_type].append(knowledge)

        merged_knowledge = []

        # 对每个知识类型分别进行LLM合并
        for knowledge_type, knowledge_group in knowledge_by_type.items():
            if len(knowledge_group) == 1:
                # 只有一个知识点，直接添加
                merged_knowledge.append(knowledge_group[0])
            else:
                # 多个知识点，使用LLM合并
                merged = self.merge_knowledge_with_llm(knowledge_group, knowledge_type)
                merged_knowledge.append(merged)

        return merged_knowledge

    def merge_knowledge_with_llm(self, knowledge_group, knowledge_type):
        """使用LLM合并同类型的知识组"""
        # 准备知识内容列表
        knowledge_contents = []
        all_keywords = set()
        all_sources = []

        for i, knowledge in enumerate(knowledge_group, 1):
            content = knowledge.get('content', '')
            confidence = knowledge.get('confidence', 0.5)
            keywords = knowledge.get('keywords', [])
            source = knowledge.get('source', '')
            category = knowledge.get('category', '')

            knowledge_contents.append(f"{i}. 内容: {content}")
            knowledge_contents.append(f"   置信度: {confidence}")
            knowledge_contents.append(f"   分类: {category}")
            knowledge_contents.append(f"   来源: {source}")
            knowledge_contents.append(f"   关键词: {', '.join(keywords)}")
            knowledge_contents.append("")

            all_keywords.update(keywords)
            if source and source not in all_sources:
                all_sources.append(source)

        # 构建LLM合并提示
        prompt = f"""
你是一个专业的知识整理专家。请将以下{knowledge_type}类型的知识点进行智能合并，生成一个更完整、准确的知识点。

### 合并要求：
1. 保留所有重要信息，避免信息丢失
2. 消除重复内容，整合相似表述
3. 提高内容的准确性和完整性
4. 保持逻辑清晰，结构合理
5. 合并后的置信度取所有知识点中的最高值

### 待合并的知识点：
{chr(10).join(knowledge_contents)}

### 请返回JSON格式：
{{
    "knowledge_type": "{knowledge_type}",
    "content": "合并后的知识内容",
    "confidence": 最高置信度值,
    "keywords": ["合并后的关键词列表"],
    "category": "合并后的分类",
    "sources": ["所有来源"],
    "frequency": {len(knowledge_group)}
}}

### 合并结果：
"""

        response = get_completion(prompt, self.model)

        # 预处理响应
        response = preprocess_json_response(response)

        try:
            result = json.loads(response)
            return result
        except json.JSONDecodeError as e:
            print(f"知识合并JSON解析失败: {e}")
            print(f"AI返回内容: {response[:200]}...")

            # 解析失败时，使用简单的合并策略
            best_knowledge = max(knowledge_group, key=lambda x: x.get('confidence', 0))
            return {
                "knowledge_type": knowledge_type,
                "content": best_knowledge['content'],
                "confidence": best_knowledge.get('confidence', 0.5),
                "frequency": len(knowledge_group),
                "keywords": list(all_keywords),
                "category": best_knowledge['category'],
                "sources": all_sources
            }
def main():
    # 初始化对话知识提取器
    extractor = ConversationKnowledgeExtractor()

    print("=== 对话知识提取与沉淀示例（迪士尼主题乐园） ===\n")

    # 示例对话数据
    sample_conversations = [
        """
用户: "我想去上海迪士尼乐园玩，门票多少钱？"
AI: "上海迪士尼乐园的门票价格根据日期有所不同。平日成人票价为399元，周末和节假日为499元。儿童票（1.0-1.4米）平日为299元，周末为374元。1.0米以下儿童免费。"
用户: "需要提前预订吗？"
AI: "建议提前预订，特别是周末和节假日，可以通过官方网站或第三方平台预订。"
用户: "从浦东机场怎么去？"
AI: "从浦东机场到迪士尼乐园可以乘坐地铁2号线到广兰路站，然后换乘11号线到迪士尼站，全程约1小时。也可以打车，约40分钟。"
""",
        """
用户: "迪士尼乐园今天开放吗？"
AI: "上海迪士尼乐园通常每天开放，营业时间为上午8:00至晚上8:00。但建议您出发前查看官方网站或APP确认具体营业时间，因为可能会因特殊活动或维护调整。"
用户: "现在人多不多？"
AI: "人流量会因日期、季节和活动而变化。周末、节假日和寒暑假通常人较多。建议您查看官方APP的实时人流量信息，或关注社交媒体上的游客分享。"
用户: "有什么必玩的项目？"
AI: "上海迪士尼乐园的必玩项目包括：创极速光轮（明日世界）、七个小矮人矿山车（梦幻世界）、加勒比海盗：战争之潮（宝藏湾）、翱翔·飞越地平线（探险岛）等。"
""",
        """
用户: "带小孩去迪士尼需要注意什么？"
AI: "带小孩去迪士尼需要注意：1. 身高限制，部分项目有身高要求；2. 准备防晒、雨具等；3. 带些零食和水；4. 建议下载官方APP查看实时排队时间；5. 可以租用婴儿车；6. 注意安全，看管好孩子。"
用户: "停车费怎么收？"
AI: "上海迪士尼乐园停车场收费为100元/天，建议提前到达，因为停车场可能会满。也可以选择地铁出行，11号线迪士尼站就在乐园门口。"
用户: "可以带食物进去吗？"
AI: "可以携带密封包装的零食和水，但不能带玻璃瓶、酒精饮料等。园内有多个餐厅和小吃店，价格相对较高，建议合理安排。"
"""
    ]

    # 示例1: 从单次对话中提取知识
    print("示例1: 从单次对话中提取知识")
    conversation = sample_conversations[0]
    print(f"对话内容:\n{conversation}")

    extracted = extractor.extract_knowledge_from_conversation(conversation)
    print(f"\n提取的知识点:")
    for i, knowledge in enumerate(extracted['extracted_knowledge'], 1):
        print(f"  {i}. 类型: {knowledge['knowledge_type']}")
        print(f"     内容: {knowledge['content']}")
        print(f"     置信度: {knowledge['confidence']}")
        print(f"     分类: {knowledge['category']}")

    print(f"\n对话摘要: {extracted['conversation_summary']}")
    print(f"用户意图: {extracted['user_intent']}")

    print("\n" + "="*60 + "\n")

    # 示例2: 批量提取知识
    print("示例2: 批量提取知识")
    all_knowledge = extractor.batch_extract_knowledge(sample_conversations)
    print(f"总共提取了 {len(all_knowledge)} 个知识点")

    # 显示所有知识点
    print(f"\n所有知识点:")
    for key, count in extractor.knowledge_frequency.most_common():
        print(f"  {key}: {count}次")

    print("\n" + "="*60 + "\n")


    # 示例3: 合并相似知识
    print("示例3: 合并相似知识")
    merged_knowledge = extractor.merge_similar_knowledge(all_knowledge)
    print(f"合并后剩余 {len(merged_knowledge)} 个知识点")

    print(f"\n合并后的知识点:")
    for i, knowledge in enumerate(merged_knowledge, 1):
        print(f"  {i}. 类型: {knowledge.get('knowledge_type', '未知')}")
        print(f"     内容: {knowledge['content']}")
        print(f"     频率: {knowledge.get('frequency', 1)}次")
        print(f"     置信度: {knowledge.get('confidence', 0.5)}")
        print(f"     分类: {knowledge.get('category', '未知')}")
        print(f"     关键词: {knowledge.get('keywords', [])}")
        print(f"     来源: {knowledge.get('sources', [])}")
        print()

    print("\n" + "="*60 + "\n")    

if __name__ == "__main__":
    main() 
```

运行结果：

```shell
=== 对话知识提取与沉淀示例（迪士尼主题乐园） ===

示例1: 从单次对话中提取知识
对话内容:

用户: "我想去上海迪士尼乐园玩，门票多少钱？"
AI: "上海迪士尼乐园的门票价格根据日期有所不同。平日成人票价为399元，周末和节假日为499元。儿童票（1.0-1.4米）平日为299元，周末为374元。1.0米以下儿童免费。"
用户: "需要提前预订吗？"
AI: "建议提前预订，特别是周末和节假日，可以通过官方网站或第三方平台预订。"
用户: "从浦东机场怎么去？"
AI: "从浦东机场到迪士尼乐园可以乘坐地铁2号线到广兰路站，然后换乘11号线到迪士尼站，全程约1小时。也可以打车，约40分钟。"


提取的知识点:
  1. 类型: 事实
     内容: 上海迪士尼乐园平日成人票价为399元，周末和节假日为499元。
     置信度: 1.0
     分类: 票价信息
  2. 类型: 事实
     内容: 儿童票（1.0-1.4米）平日为299元，周末为374元；1.0米以下儿童免费。
     置信度: 1.0
     分类: 票价信息
  3. 类型: 需求
     内容: 用户希望了解上海迪士尼乐园的门票价格、是否需要提前预订以及从浦东机场前往的方式。
     置信度: 0.95
     分类: 出行计划
  4. 类型: 流程
     内容: 从浦东机场到上海迪士尼乐园可乘坐地铁2号线到广兰路站，再换乘11号线到迪士尼站，全程约1小时。
     置信度: 0.9
     分类: 交通指南
  5. 类型: 流程
     内容: 从浦东机场打车前往上海迪士尼乐园约需40分钟。
     置信度: 0.85
     分类: 交通指南
  6. 类型: 注意
     内容: 建议提前预订门票，特别是周末和节假日，以确保入园资格。
     置信度: 0.95
     分类: 购票提醒

对话摘要: 用户咨询上海迪士尼乐园门票价格、是否需要提前预订以及从浦东机场前往的交通方式。AI提供了详细的票价信息、推荐的交通路线（地铁和打车），并提醒用户在高峰时段提前购票。
用户意图: 获取上海迪士尼乐园游玩相关信息，包括票价、预订方式和交通路线，以便规划行程。

============================================================

示例2: 批量提取知识
正在处理对话 1/3...
正在处理对话 2/3...
正在处理对话 3/3...
总共提取了 22 个知识点

所有知识点:
  事实:上海迪士尼乐园平日成人票价为399元，周末和节假日为499元。: 1次
  事实:儿童票（1.0-1.4米）平日为299元，周末为374元；1.0米以下儿童免费。: 1次
  需求:用户希望了解上海迪士尼乐园的门票价格、预订方式及从浦东机场前往的交通方式。: 1次
  流程:从浦东机场到上海迪士尼乐园可乘坐地铁2号线至广兰路站，换乘11号线至迪士尼站，全程约1小时。: 1次
  流程:建议提前通过官方网站或第三方平台预订门票，尤其在周末和节假日。: 1次
  注意:周末和节假日门票价格更高，且建议提前预订以避免现场无票。: 1次
  事实:上海迪士尼乐园通常每天开放，营业时间为上午8:00至晚上8:00。: 1次
  事实:上海迪士尼乐园的必玩项目包括：创极速光轮（明日世界）、七个小矮人矿山车（梦幻世界）、加勒比海盗：战争: 1次
  需求:用户想知道当前迪士尼乐园是否开放、人流量情况以及值得游玩的项目。: 1次
  问题:用户询问迪士尼乐园今天是否开放、现在人多不多、有什么必玩项目。: 1次
  流程:建议用户出发前查看上海迪士尼官方网站或APP确认具体营业时间；查看官方APP的实时人流量信息，或关注: 1次
  注意:上海迪士尼乐园的营业时间可能因特殊活动或维护调整，建议出发前再次确认。: 1次
  事实:上海迪士尼乐园停车场收费为100元/天。: 1次
  事实:部分游乐项目有身高限制，需注意儿童是否符合要求。: 1次
  事实:可以携带密封包装的零食和水进入园区，但禁止带玻璃瓶和酒精饮料。: 1次
  需求:用户希望了解带小孩去迪士尼时需要准备的事项，包括安全、便利性和舒适性。: 1次
  流程:建议下载官方APP查看实时排队时间，以优化游玩体验。: 1次
  流程:可租用婴儿车，方便带小孩出行。: 1次
  问题:用户询问停车费如何收取？: 1次
  问题:用户询问是否可以带食物进入园区？: 1次
  注意:建议提前到达停车场，因为可能满位；也可选择地铁出行（11号线迪士尼站）。: 1次
  注意:园内餐饮价格较高，建议自带适量零食和水以节省开支。: 1次

============================================================

示例3: 合并相似知识
过滤前知识点数量: 22
过滤后知识点数量: 16
过滤掉的'需求'和'问题'类型知识点: 6
合并后剩余 3 个知识点

合并后的知识点:
  1. 类型: 事实
     内容: 上海迪士尼乐园门票价格为：成人票平日399元，周末及节假日499元；儿童票（身高1.0-1.4米）平日299元，周末374元，1.0米以下儿童免费。园区通常每天开放，营业时间为上午8:00至晚上8:00。必玩项目包括创极速光轮（明日世界）、七个小矮人矿山车（梦幻世界）、加勒比海盗：战争之潮（宝藏湾）和翱翔·飞越地平线（探险岛）。部分游乐项目设有身高限制，需注意儿童是否符合要求。园内允许携带密封包装的零食和水，但禁止携带玻璃瓶及酒精饮料。园区停车场收费为100元/天。
     频率: 7次
     置信度: 0.95
     分类: 综合入园指南
     关键词: ['门票价格', '上海迪士尼', '成人票', '儿童票', '身高标准', '营业时间', '开放', '必玩项目', '创极速光轮', '七个小矮人矿山车', '加勒比海盗', '翱翔·飞越地平线', '身高限制', '游乐项目', '食物携带', '园内规定', '停车费']
     来源: ['AI']

  2. 类型: 流程
     内容: 从浦东机场前往上海迪士尼乐园，建议乘坐地铁2号线至广兰路站，换乘11号线至迪士尼站，全程约1小时。出行前应通过上海迪士尼官方网站或APP确认当日营业时间，并查看实时人流量信息（可通过官方APP或关注社交媒体游客分享）以合理安排行程。为优化游玩体验，建议提前通过官网或第三方平台预订门票（尤其在周末和节假日），并下载官方APP查看各游乐设施的实时排队时间。园内可租用婴儿车，方便带小孩家庭出行。
     频率: 5次
     置信度: 0.92
     分类: 出行与游玩全流程
     关键词: ['地铁', '交通路线', '浦东机场', '预订', '官网', '第三方平台', '出行准备', '官方APP', '实时人流量', '社交媒体', '排队时间', '婴儿车', '租赁']
     来源: ['AI']

  3. 类型: 注意
     内容: 周末和节假日门票价格更高，建议提前预订以避免现场无票；园内营业时间可能因特殊活动或维护调整，出行前请再次确认；停车场可能满位，建议提前到达或选择地铁（11号线迪士尼站）出行；园内餐饮价格较高，建议自带适量零食和水以节省开支。
     频率: 4次
     置信度: 0.9
     分类: 提醒事项
     关键词: ['节假日票价', '提前预订', '票务紧张', '营业时间调整', '特殊活动', '维护', '停车', '交通方式', '餐饮价格', '自备食物']
     来源: ['AI']


============================================================
```

### 3、知识库健康度检查

对整个知识库进行健康度检查，找出缺少的知识、过期的知识、冲突的知识，确保知识库的质量和可靠性。

##### 核心功能：

1、完整性检查：评估知识库是否覆盖用户的主要查询需求

2、时效性检查：识别过期或需要更新的知识内容

3、一致性检查：发现知识库中的冲突和矛盾信息

4、综合评分：提供量化的健康度评分和改进建议

##### 完整案例：

```python
# 知识库健康度检查
# 导入依赖库
import dashscope
import os
import json
import re
from datetime import datetime

# 从环境变量中获取 API Key
dashscope.api_key = "xxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

# 基于 prompt 生成文本
def get_completion(prompt, model="qwen-turbo-latest"):
    messages = [{"role": "user", "content": prompt}]
    response = dashscope.Generation.call(
        model=model,
        messages=messages,
        result_format='message',
        temperature=0.3,
    )
    return response.output.choices[0].message.content

class KnowledgeBaseHealthChecker:
    def __init__(self, model="qwen-turbo-latest"):
        self.model = model
        self.health_report = {}

    def check_missing_knowledge(self, knowledge_base, test_queries):
        """使用LLM检查缺少的知识"""
        instruction = """
你是一个知识库完整性检查专家。请分析给定的测试查询和知识库内容，判断知识库中是否缺少相关的知识。

检查标准：
1. 查询是否能在知识库中找到相关答案
2. 知识是否完整、准确
3. 是否覆盖了用户的主要需求
4. 是否存在知识空白

请返回JSON格式：
{
    "missing_knowledge": [
        {
            "query": "测试查询",
            "missing_aspect": "缺少的知识方面",
            "importance": "重要性（高/中/低）",
            "suggested_content": "建议的知识内容",
            "category": "知识分类"
        }
    ],
    "coverage_score": "覆盖率评分(0-1)",
    "completeness_analysis": "完整性分析"
}
"""

        # 构建知识库内容摘要
        knowledge_summary = []
        for chunk in knowledge_base:
            knowledge_summary.append(f"ID: {chunk.get('id', 'unknown')} - {chunk.get('content', '')}")

        knowledge_text = "\n".join(knowledge_summary)

        # 构建测试查询列表
        queries_text = []
        for query_info in test_queries:
            query = query_info['query']
            expected = query_info.get('expected_answer', '')
            queries_text.append(f"查询: {query} | 期望答案: {expected}")

        queries_text = "\n".join(queries_text)

        prompt = f"""
### 指令 ###
{instruction}

### 知识库内容 ###
{knowledge_text}

### 测试查询 ###
{queries_text}

### 分析结果 ###
"""

        try:
            response = get_completion(prompt, self.model)

            # 预处理响应，移除markdown代码块格式
            if response.startswith('```json'):
                response = response[7:]
            elif response.startswith('```'):
                response = response[3:]
            if response.endswith('```'):
                response = response[:-3]

            result = json.loads(response.strip())
            return result

        except Exception as e:
            print(f"LLM检查缺少知识失败: {e}")
            return None

    def check_outdated_knowledge(self, knowledge_base):
        """使用LLM检查过期的知识"""
        instruction = """
你是一个知识时效性检查专家。请分析给定的知识内容，判断是否存在过期或需要更新的信息。

检查标准：
1. 时间相关信息是否过期（年份、日期、时间范围）
2. 价格信息是否最新（价格、费用、票价等）
3. 政策规则是否更新（政策、规定、规则等）
4. 活动信息是否有效（活动、节日、特殊安排等）
5. 联系方式是否准确（电话、地址、网址等）
6. 技术信息是否过时（版本、技术标准等）

请返回JSON格式：
{
    "outdated_knowledge": [
        {
            "chunk_id": "知识切片ID",
            "content": "知识内容",
            "outdated_aspect": "过期方面",
            "severity": "严重程度（高/中/低）",
            "suggested_update": "建议更新内容",
            "last_verified": "最后验证时间"
        }
    ],
    "freshness_score": "新鲜度评分(0-1)",
    "update_recommendations": "更新建议"
}
"""

        # 构建知识库内容
        knowledge_text = []
        for chunk in knowledge_base:
            content = chunk.get('content', '')
            chunk_id = chunk.get('id', 'unknown')
            last_updated = chunk.get('last_updated', 'unknown')
            knowledge_text.append(f"ID: {chunk_id} | 更新时间: {last_updated} | 内容: {content}")

        knowledge_text = "\n".join(knowledge_text)

        prompt = f"""
### 指令 ###
{instruction}

### 知识库内容 ###
{knowledge_text}

### 当前时间 ###
{datetime.now().strftime('%Y年%m月%d日')}

### 分析结果 ###
"""

        try:
            response = get_completion(prompt, self.model)

            # 预处理响应，移除markdown代码块格式
            if response.startswith('```json'):
                response = response[7:]
            elif response.startswith('```'):
                response = response[3:]
            if response.endswith('```'):
                response = response[:-3]

            result = json.loads(response.strip())
            return result

        except Exception as e:
            print(f"LLM检查过期知识失败: {e}")
            return None
    def check_conflicting_knowledge(self, knowledge_base):
        """使用LLM检查冲突的知识"""
        instruction = """
你是一个知识一致性检查专家。请分析给定的知识库，找出可能存在冲突或矛盾的信息。

检查标准：
1. 同一主题的不同说法（地点、名称、描述等）
2. 价格信息的差异（价格、费用、收费标准等）
3. 时间信息的不一致（营业时间、开放时间、活动时间等）
4. 规则政策的冲突（规定、政策、要求等）
5. 操作流程的差异（步骤、方法、流程等）
6. 联系方式的差异（地址、电话、网址等）

请返回JSON格式：
{
    "conflicting_knowledge": [
        {
            "conflict_type": "冲突类型",
            "chunk_ids": ["相关切片ID"],
            "conflicting_content": ["冲突内容"],
            "severity": "严重程度（高/中/低）",
            "resolution_suggestion": "解决建议"
        }
    ],
    "consistency_score": "一致性评分(0-1)",
    "conflict_analysis": "冲突分析"
}
"""

        # 构建知识库内容
        knowledge_text = []
        for chunk in knowledge_base:
            content = chunk.get('content', '')
            chunk_id = chunk.get('id', 'unknown')
            knowledge_text.append(f"ID: {chunk_id} | 内容: {content}")

        knowledge_text = "\n".join(knowledge_text)

        prompt = f"""
### 指令 ###
{instruction}

### 知识库内容 ###
{knowledge_text}

### 分析结果 ###
"""

        try:
            response = get_completion(prompt, self.model)

            # 预处理响应，移除markdown代码块格式
            if response.startswith('```json'):
                response = response[7:]
            elif response.startswith('```'):
                response = response[3:]
            if response.endswith('```'):
                response = response[:-3]

            result = json.loads(response.strip())
            return result

        except Exception as e:
            print(f"LLM检查冲突知识失败: {e}")
            return None

    def calculate_overall_health_score(self, missing_result, outdated_result, conflicting_result):
        """计算整体健康度评分"""
        coverage_score = missing_result.get('coverage_score', 0)
        freshness_score = outdated_result.get('freshness_score', 0)
        consistency_score = conflicting_result.get('consistency_score', 0)

        # 加权计算
        overall_score = (
            coverage_score * 0.4 +      # 覆盖率权重40%
            freshness_score * 0.3 +     # 新鲜度权重30%
            consistency_score * 0.3      # 一致性权重30%
        )

        return overall_score

    def generate_health_report(self, knowledge_base, test_queries):
        """生成完整的健康度报告"""
        print("正在检查知识库健康度...")

        # 1. 检查缺少的知识
        print("1. 检查缺少的知识...")
        missing_result = self.check_missing_knowledge(knowledge_base, test_queries)

        # 2. 检查过期的知识
        print("2. 检查过期的知识...")
        outdated_result = self.check_outdated_knowledge(knowledge_base)

        # 3. 检查冲突的知识
        print("3. 检查冲突的知识...")
        conflicting_result = self.check_conflicting_knowledge(knowledge_base)

        # 4. 计算整体健康度
        overall_score = self.calculate_overall_health_score(missing_result, outdated_result, conflicting_result)

        # 5. 生成报告
        report = {
            "overall_health_score": overall_score,
            "health_level": self.get_health_level(overall_score),
            "missing_knowledge": missing_result,
            "outdated_knowledge": outdated_result,
            "conflicting_knowledge": conflicting_result,
            "recommendations": self.generate_recommendations(missing_result, outdated_result, conflicting_result),
            "check_date": datetime.now().isoformat()
        }

        return report

    def get_health_level(self, score):
        """根据评分确定健康等级"""
        if score >= 0.8:
            return "优秀"
        elif score >= 0.6:
            return "良好"
        elif score >= 0.4:
            return "一般"
        else:
            return "需要改进"

    def generate_recommendations(self, missing_result, outdated_result, conflicting_result):
        """生成改进建议"""
        recommendations = []

        # 基于缺少知识的建议
        missing_count = len(missing_result.get('missing_knowledge', []))
        if missing_count > 0:
            recommendations.append(f"补充{missing_count}个缺少的知识点，提高覆盖率")

        # 基于过期知识的建议
        outdated_count = len(outdated_result.get('outdated_knowledge', []))
        if outdated_count > 0:
            recommendations.append(f"更新{outdated_count}个过期知识点，确保信息时效性")

        # 基于冲突知识的建议
        conflicting_count = len(conflicting_result.get('conflicting_knowledge', []))
        if conflicting_count > 0:
            recommendations.append(f"解决{conflicting_count}个知识冲突，提高一致性")

        if not recommendations:
            recommendations.append("知识库状态良好，建议定期维护")

        return recommendations

def main():
    # 初始化知识库健康度检查器
    checker = KnowledgeBaseHealthChecker()

    print("=== 知识库健康度检查示例（迪士尼主题乐园） ===\n")

    # 示例知识库（包含一些故意的问题）
    knowledge_base = [
        {
            "id": "kb_001",
            "content": "上海迪士尼乐园位于上海市浦东新区，是中国大陆首座迪士尼主题乐园，于2016年6月16日开园。乐园占地面积390公顷，包含七大主题园区。",
            "last_updated": "2024-01-15"
        },
        {
            "id": "kb_002",
            "content": "上海迪士尼乐园的门票价格：平日成人票价为399元，周末和节假日为499元。儿童票平日为299元，周末为374元。",
            "last_updated": "2023-12-01"  # 故意设置为较旧的时间
        },
        {
            "id": "kb_003",
            "content": "上海迪士尼乐园门票价格：成人票平日350元，周末450元。儿童票平日250元，周末350元。",  # 故意设置冲突的价格
            "last_updated": "2024-02-01"
        },
        {
            "id": "kb_004",
            "content": "上海迪士尼乐园营业时间为上午8:00至晚上8:00，全年无休。",
            "last_updated": "2024-01-20"
        },
        {
            "id": "kb_005",
            "content": "从上海市区到迪士尼乐园可以乘坐地铁11号线到迪士尼站，或乘坐迪士尼专线巴士。",
            "last_updated": "2024-01-10"
        }
    ]

    # 测试查询
    test_queries = [
        {
            "query": "上海迪士尼乐园在哪里？",
            "expected_answer": "浦东新区"
        },
        {
            "query": "门票多少钱？",
            "expected_answer": "价格信息"
        },
        {
            "query": "营业时间是什么？",
            "expected_answer": "8:00-20:00"
        },
        {
            "query": "怎么去迪士尼？",
            "expected_answer": "地铁11号线"
        },
        {
            "query": "有什么特别活动？",  # 知识库中没有相关信息
            "expected_answer": "活动信息"
        },
        {
            "query": "停车费是多少？",  # 知识库中没有相关信息
            "expected_answer": "停车费信息"
        }
    ]

    # 生成健康度报告
    health_report = checker.generate_health_report(knowledge_base, test_queries)

    # 显示报告
    print("=== 知识库健康度报告 ===\n")

    print(f"整体健康度评分: {health_report['overall_health_score']:.2f}")
    print(f"健康等级: {health_report['health_level']}")
    print(f"检查时间: {health_report['check_date']}")

    print("\n" + "="*60 + "\n")

    # 详细分析
    print("=== 详细分析 ===\n")

    # 1. 缺少的知识
    print("1. 缺少的知识分析:")
    missing = health_report['missing_knowledge']
    print(f"   覆盖率: {health_report['missing_knowledge']['coverage_score']*100:.1f}%")
    print(f"   缺少知识点数量: {len(missing['missing_knowledge'])}")
    for i, item in enumerate(missing['missing_knowledge'][:3], 1):
        print(f"   {i}. 查询: {item['query']}")
        print(f"      缺少方面: {item['missing_aspect']}")
        print(f"      重要性: {item['importance']}")

    print("\n" + "-"*40 + "\n")

    # 2. 过期的知识
    print("2. 过期的知识分析:")
    outdated = health_report['outdated_knowledge']
    print(f"   新鲜度评分: {outdated['freshness_score']:.2f}")
    print(f"   过期知识点数量: {len(outdated['outdated_knowledge'])}")
    for i, item in enumerate(outdated['outdated_knowledge'][:3], 1):
        print(f"   {i}. 切片ID: {item['chunk_id']}")
        print(f"      过期方面: {item['outdated_aspect']}")
        print(f"      严重程度: {item['severity']}")

    print("\n" + "-"*40 + "\n")

    # 3. 冲突的知识
    print("3. 冲突的知识分析:")
    conflicting = health_report['conflicting_knowledge']
    print(f"   一致性评分: {conflicting['consistency_score']:.2f}")
    print(f"   冲突数量: {len(conflicting['conflicting_knowledge'])}")
    for i, item in enumerate(conflicting['conflicting_knowledge'][:3], 1):
        print(f"   {i}. 冲突类型: {item['conflict_type']}")
        print(f"      相关切片: {item['chunk_ids']}")
        print(f"      严重程度: {item['severity']}")

    print("\n" + "="*60 + "\n")

    # 改进建议
    print("=== 改进建议 ===\n")
    for i, recommendation in enumerate(health_report['recommendations'], 1):
        print(f"{i}. {recommendation}")

if __name__ == "__main__":
    main() 
```

运行结果：

```shell
=== 知识库健康度检查示例（迪士尼主题乐园） ===

正在检查知识库健康度...
1. 检查缺少的知识...
2. 检查过期的知识...
3. 检查冲突的知识...
=== 知识库健康度报告 ===

整体健康度评分: 0.60
健康等级: 良好
检查时间: 2025-12-06T23:27:30.953240

============================================================

=== 详细分析 ===

1. 缺少的知识分析:
   覆盖率: 60.0%
   缺少知识点数量: 2
   1. 查询: 有什么特别活动？
      缺少方面: 乐园内的特别活动信息（如节日庆典、演出、限时活动等）
      重要性: 高
   2. 查询: 停车费是多少？
      缺少方面: 停车场收费标准及停车指南
      重要性: 中

----------------------------------------

2. 过期的知识分析:
   新鲜度评分: 0.60
   过期知识点数量: 2
   1. 切片ID: kb_002
      过期方面: 价格信息
      严重程度: 高
   2. 切片ID: kb_004
      过期方面: 活动信息
      严重程度: 中

----------------------------------------

3. 冲突的知识分析:
   一致性评分: 0.60
   冲突数量: 2
   1. 冲突类型: 价格信息的差异
      相关切片: ['kb_002', 'kb_003']
      严重程度: 高
   2. 冲突类型: 时间信息的不一致
      相关切片: ['kb_004']
      严重程度: 中

============================================================

=== 改进建议 ===

1. 补充2个缺少的知识点，提高覆盖率
2. 更新2个过期知识点，确保信息时效性
3. 解决2个知识冲突，提高一致性
```

### 4、知识库版本管理与性能比较

对知识库进行版本管理，实现回归测试、上线前验收，并比较不同版本的知识库性能，选择
最优版本。

##### 核心功能

1、版本创建：为知识库创建带描述和统计信息的版本

2、哈希值计算：使用MD5计算版本的唯一标识

3、统计信息：记录知识切片数量、内容长度、分类分布等

4、版本比较：比较两个版本的差异和变化

##### 完整代码

```python
# 知识库版本管理与性能比较
# 导入依赖库
import dashscope
import os
import json
import re
from datetime import datetime, timedelta
from collections import defaultdict, Counter
import pandas as pd
import numpy as np
import faiss
from openai import OpenAI

# 从环境变量中获取 API Key
dashscope.api_key = "xxxxxxxxxxxxxxxxxxxxxxxxxxx"

# 初始化百炼兼容的 OpenAI 客户端
client = OpenAI(
    api_key=dashscope.api_key,
    base_url="https://dashscope.aliyuncs.com/compatible-mode/v1"
)

# 全局配置
TEXT_EMBEDDING_MODEL = "text-embedding-v4"
TEXT_EMBEDDING_DIM = 1024

# 基于 prompt 生成文本
def get_completion(prompt, model="qwen-turbo-latest"):
    messages = [{"role": "user", "content": prompt}]
    response = dashscope.Generation.call(
        model=model,
        messages=messages,
        result_format='message',
        temperature=0.3,
    )
    return response.output.choices[0].message.content

def get_text_embedding(text):
    """获取文本的 Embedding"""
    response = client.embeddings.create(
        model=TEXT_EMBEDDING_MODEL,
        input=text,
        dimensions=TEXT_EMBEDDING_DIM
    )
    return response.data[0].embedding

class KnowledgeBaseVersionManager:
    def __init__(self, model="qwen-turbo-latest"):
        self.model = model
        self.versions = {}

    def create_version(self, knowledge_base, version_name, description=""):
        """创建知识库版本"""
        # 构建向量索引
        metadata_store, text_index = self.build_vector_index(knowledge_base)

        version_info = {
            "version_name": version_name,
            "description": description,
            "created_date": datetime.now().isoformat(),
            "knowledge_base": knowledge_base,
            "metadata_store": metadata_store,
            "text_index": text_index,
            "statistics": self.calculate_version_statistics(knowledge_base)
        }

        self.versions[version_name] = version_info
        return version_info

    def build_vector_index(self, knowledge_base):
        """构建向量索引"""
        metadata_store = []
        text_vectors = []

        for i, chunk in enumerate(knowledge_base):
            content = chunk.get('content', '')
            if not content.strip():
                continue

            metadata = {
                "id": i,
                "content": content,
                "chunk_id": chunk.get('id', f'chunk_{i}')
            }

            # 获取文本embedding
            vector = get_text_embedding(content)
            text_vectors.append(vector)
            metadata_store.append(metadata)

        # 创建FAISS索引
        text_index = faiss.IndexFlatL2(TEXT_EMBEDDING_DIM)
        text_index_map = faiss.IndexIDMap(text_index)

        if text_vectors:
            text_ids = [m["id"] for m in metadata_store]
            text_index_map.add_with_ids(np.array(text_vectors).astype('float32'), np.array(text_ids))

        return metadata_store, text_index_map

    def calculate_version_statistics(self, knowledge_base):
        """计算版本统计信息"""
        total_chunks = len(knowledge_base)
        total_content_length = sum(len(chunk.get('content', '')) for chunk in knowledge_base)

        return {
            "total_chunks": total_chunks,
            "total_content_length": total_content_length,
            "average_chunk_length": total_content_length / total_chunks if total_chunks > 0 else 0
        }

    def compare_versions(self, version1_name, version2_name):
        """比较两个版本的差异"""
        if version1_name not in self.versions or version2_name not in self.versions:
            return {"error": "版本不存在"}

        v1 = self.versions[version1_name]
        v2 = self.versions[version2_name]

        kb1 = v1['knowledge_base']
        kb2 = v2['knowledge_base']

        comparison = {
            "version1": version1_name,
            "version2": version2_name,
            "comparison_date": datetime.now().isoformat(),
            "changes": self.detect_changes(kb1, kb2),
            "statistics_comparison": self.compare_statistics(v1['statistics'], v2['statistics'])
        }

        return comparison

    def detect_changes(self, kb1, kb2):
        """检测知识库变化"""
        changes = {
            "added_chunks": [],
            "removed_chunks": [],
            "modified_chunks": [],
            "unchanged_chunks": []
        }

        # 创建ID映射
        kb1_dict = {chunk.get('id'): chunk for chunk in kb1}
        kb2_dict = {chunk.get('id'): chunk for chunk in kb2}

        # 检测新增和删除
        kb1_ids = set(kb1_dict.keys())
        kb2_ids = set(kb2_dict.keys())

        added_ids = kb2_ids - kb1_ids
        removed_ids = kb1_ids - kb2_ids
        common_ids = kb1_ids & kb2_ids

        # 记录新增的知识切片
        for chunk_id in added_ids:
            changes["added_chunks"].append({
                "id": chunk_id,
                "content": kb2_dict[chunk_id].get('content', '')
            })

        # 记录删除的知识切片
        for chunk_id in removed_ids:
            changes["removed_chunks"].append({
                "id": chunk_id,
                "content": kb1_dict[chunk_id].get('content', '')
            })

        # 检测修改的知识切片
        for chunk_id in common_ids:
            chunk1 = kb1_dict[chunk_id]
            chunk2 = kb2_dict[chunk_id]

            if chunk1.get('content') != chunk2.get('content'):
                changes["modified_chunks"].append({
                    "id": chunk_id,
                    "old_content": chunk1.get('content', ''),
                    "new_content": chunk2.get('content', '')
                })
            else:
                changes["unchanged_chunks"].append(chunk_id)

        return changes

    def compare_statistics(self, stats1, stats2):
        """比较统计信息"""
        comparison = {}

        for key in stats1.keys():
            if key in stats2:
                if isinstance(stats1[key], (int, float)):
                    comparison[key] = {
                        "version1": stats1[key],
                        "version2": stats2[key],
                        "difference": stats2[key] - stats1[key],
                        "percentage_change": ((stats2[key] - stats1[key]) / stats1[key] * 100) if stats1[key] != 0 else 0
                    }
                elif isinstance(stats1[key], dict):
                    comparison[key] = self.compare_dict_statistics(stats1[key], stats2[key])

        return comparison

    def compare_dict_statistics(self, dict1, dict2):
        """比较字典类型的统计信息"""
        comparison = {}
        all_keys = set(dict1.keys()) | set(dict2.keys())

        for key in all_keys:
            val1 = dict1.get(key, 0)
            val2 = dict2.get(key, 0)
            comparison[key] = {
                "version1": val1,
                "version2": val2,
                "difference": val2 - val1
            }

        return comparison

    def evaluate_version_performance(self, version_name, test_queries):
        """评估版本性能"""
        if version_name not in self.versions:
            return {"error": "版本不存在"}

        performance_metrics = {
            "version_name": version_name,
            "evaluation_date": datetime.now().isoformat(),
            "query_results": [],
            "overall_metrics": {}
        }

        total_queries = len(test_queries)
        correct_answers = 0
        response_times = []

        for query_info in test_queries:
            query = query_info['query']
            expected_answer = query_info.get('expected_answer', '')

            # 使用embedding检索
            start_time = datetime.now()
            retrieved_chunks = self.retrieve_relevant_chunks(query, version_name)
            end_time = datetime.now()

            response_time = (end_time - start_time).total_seconds()
            response_times.append(response_time)

            # 评估检索质量
            is_correct = self.evaluate_retrieval_quality(query, retrieved_chunks, expected_answer)
            if is_correct:
                correct_answers += 1

            performance_metrics["query_results"].append({
                "query": query,
                "retrieved_chunks": len(retrieved_chunks),
                "response_time": response_time,
                "is_correct": is_correct
            })

        # 计算整体指标
        accuracy = correct_answers / total_queries if total_queries > 0 else 0
        avg_response_time = sum(response_times) / len(response_times) if response_times else 0

        performance_metrics["overall_metrics"] = {
            "accuracy": accuracy,
            "avg_response_time": avg_response_time,
            "total_queries": total_queries,
            "correct_answers": correct_answers
        }

        return performance_metrics

    def retrieve_relevant_chunks(self, query, version_name, k=3):
        """使用embedding和faiss检索相关知识切片"""
        if version_name not in self.versions:
            return []

        version_info = self.versions[version_name]
        metadata_store = version_info['metadata_store']
        text_index = version_info['text_index']

        # 获取查询的embedding
        query_vector = np.array([get_text_embedding(query)]).astype('float32')

        # 使用faiss进行检索
        distances, indices = text_index.search(query_vector, k)

        relevant_chunks = []
        for i, doc_id in enumerate(indices[0]):
            if doc_id != -1:  # faiss返回-1表示没有找到匹配
                # 通过ID在元数据中查找
                match = next((item for item in metadata_store if item["id"] == doc_id), None)
                if match:
                    # 构造返回的知识切片格式
                    chunk = {
                        "id": match["chunk_id"],
                        "content": match["content"],
                        "similarity_score": 1.0 / (1.0 + distances[0][i])  # 将距离转换为相似度
                    }
                    relevant_chunks.append(chunk)

        return relevant_chunks

    def evaluate_retrieval_quality(self, query, retrieved_chunks, expected_answer):
        """评估检索质量"""
        if not retrieved_chunks:
            return False

        # 简化的质量评估
        for chunk in retrieved_chunks:
            content = chunk.get('content', '').lower()
            if expected_answer.lower() in content:
                return True

        return False

    def compare_version_performance(self, version1_name, version2_name, test_queries):
        """比较两个版本的性能"""
        perf1 = self.evaluate_version_performance(version1_name, test_queries)
        perf2 = self.evaluate_version_performance(version2_name, test_queries)

        if "error" in perf1 or "error" in perf2:
            return {"error": "版本评估失败"}

        comparison = {
            "version1": version1_name,
            "version2": version2_name,
            "comparison_date": datetime.now().isoformat(),
            "performance_comparison": {
                "accuracy": {
                    "version1": perf1["overall_metrics"]["accuracy"],
                    "version2": perf2["overall_metrics"]["accuracy"],
                    "improvement": perf2["overall_metrics"]["accuracy"] - perf1["overall_metrics"]["accuracy"]
                },
                "response_time": {
                    "version1": perf1["overall_metrics"]["avg_response_time"],
                    "version2": perf2["overall_metrics"]["avg_response_time"],
                    "improvement": perf1["overall_metrics"]["avg_response_time"] - perf2["overall_metrics"]["avg_response_time"]
                }
            },
            "recommendation": self.generate_performance_recommendation(perf1, perf2)
        }

        return comparison

    def generate_performance_recommendation(self, perf1, perf2):
        """生成性能建议"""
        acc1 = perf1["overall_metrics"]["accuracy"]
        acc2 = perf2["overall_metrics"]["accuracy"]
        time1 = perf1["overall_metrics"]["avg_response_time"]
        time2 = perf2["overall_metrics"]["avg_response_time"]

        if acc2 > acc1 and time2 <= time1:
            return f"推荐使用版本2，准确率提升{(acc2-acc1)*100:.1f}%，响应时间{'提升' if time2 < time1 else '相当'}"
        elif acc2 > acc1 and time2 > time1:
            return f"版本2准确率更高但响应时间较长，需要权衡"
        elif acc2 < acc1 and time2 < time1:
            return f"版本2响应更快但准确率较低，需要权衡"
        else:
            return f"推荐使用版本1，性能更优"

    def generate_regression_test(self, version_name, test_queries):
        """生成回归测试"""
        if version_name not in self.versions:
            return {"error": "版本不存在"}

        regression_results = {
            "version_name": version_name,
            "test_date": datetime.now().isoformat(),
            "test_results": [],
            "pass_rate": 0
        }

        passed_tests = 0
        total_tests = len(test_queries)

        for query_info in test_queries:
            query = query_info['query']
            expected_answer = query_info.get('expected_answer', '')

            # 执行测试
            retrieved_chunks = self.retrieve_relevant_chunks(query, version_name)
            is_passed = self.evaluate_retrieval_quality(query, retrieved_chunks, expected_answer)

            if is_passed:
                passed_tests += 1

            regression_results["test_results"].append({
                "query": query,
                "expected": expected_answer,
                "retrieved": len(retrieved_chunks),
                "passed": is_passed
            })

        regression_results["pass_rate"] = passed_tests / total_tests if total_tests > 0 else 0

        return regression_results

def main():
    # 初始化版本管理器
    version_manager = KnowledgeBaseVersionManager()

    print("=== 知识库版本管理与性能比较示例（迪士尼主题乐园） ===\n")

    # 创建版本1（基础版本）
    knowledge_base_v1 = [
        {
            "id": "kb_001",
            "content": "上海迪士尼乐园位于上海市浦东新区，是中国大陆首座迪士尼主题乐园，于2016年6月16日开园。"
        },
        {
            "id": "kb_002",
            "content": "上海迪士尼乐园的门票价格：平日成人票价为399元，周末和节假日为499元。"
        },
        {
            "id": "kb_003",
            "content": "上海迪士尼乐园营业时间为上午8:00至晚上8:00。"
        }
    ]

    # 创建版本2（增强版本）
    knowledge_base_v2 = [
        {
            "id": "kb_001",
            "content": "上海迪士尼乐园位于上海市浦东新区，是中国大陆首座迪士尼主题乐园，于2016年6月16日开园。乐园占地面积390公顷，包含七大主题园区。"
        },
        {
            "id": "kb_002",
            "content": "上海迪士尼乐园的门票价格：平日成人票价为399元，周末和节假日为499元。儿童票（1.0-1.4米）平日为299元，周末为374元。1.0米以下儿童免费。"
        },
        {
            "id": "kb_003",
            "content": "上海迪士尼乐园营业时间为上午8:00至晚上8:00，全年无休。建议出发前查看官方网站确认具体时间。"
        },
        {
            "id": "kb_004",
            "content": "从上海市区到迪士尼乐园可以乘坐地铁11号线到迪士尼站，或乘坐迪士尼专线巴士。"
        },
        {
            "id": "kb_005",
            "content": "上海迪士尼乐园的特色项目包括：创极速光轮、七个小矮人矿山车、加勒比海盗等。"
        }
    ]

    # 功能1: 创建版本
    print("功能1: 创建知识库版本")
    v1_info = version_manager.create_version(knowledge_base_v1, "v1.0", "基础版本")
    v2_info = version_manager.create_version(knowledge_base_v2, "v2.0", "增强版本")

    print(f"版本1信息:")
    print(f"  版本名: {v1_info['version_name']}")
    print(f"  描述: {v1_info['description']}")
    print(f"  知识切片数量: {v1_info['statistics']['total_chunks']}")
    print(f"  平均切片长度: {v1_info['statistics']['average_chunk_length']:.0f}字符")

    print(f"\n版本2信息:")
    print(f"  版本名: {v2_info['version_name']}")
    print(f"  描述: {v2_info['description']}")
    print(f"  知识切片数量: {v2_info['statistics']['total_chunks']}")
    print(f"  平均切片长度: {v2_info['statistics']['average_chunk_length']:.0f}字符")

    print("\n" + "="*60 + "\n")

    # 功能示例2: 版本比较
    print("功能2: 版本差异比较")
    comparison = version_manager.compare_versions("v1.0", "v2.0")

    print(f"版本比较结果:")
    changes = comparison['changes']
    print(f"  新增知识切片: {len(changes['added_chunks'])}个")
    print(f"  删除知识切片: {len(changes['removed_chunks'])}个")
    print(f"  修改知识切片: {len(changes['modified_chunks'])}个")

    print(f"\n新增的知识切片:")
    for i, chunk in enumerate(changes['added_chunks'], 1):
        print(f"  {i}. ID: {chunk['id']}")
        print(f"     内容: {chunk['content']}")

    print(f"\n修改的知识切片:")
    for i, chunk in enumerate(changes['modified_chunks'], 1):
        print(f"  {i}. ID: {chunk['id']}")
        print(f"     旧内容: {chunk['old_content']}")
        print(f"     新内容: {chunk['new_content']}")

    print("\n" + "="*60 + "\n")

    # 功能3: 性能评估
    print("功能3: 版本性能评估")

    test_queries = [
        {"query": "上海迪士尼乐园在哪里？", "expected_answer": "浦东新区"}, # 关键词包含即正确
        {"query": "门票多少钱？", "expected_answer": "价格"},
        {"query": "营业时间是什么？", "expected_answer": "8:00"},
        {"query": "怎么去迪士尼？", "expected_answer": "地铁"},
        {"query": "有什么好玩的项目？", "expected_answer": "项目"}
    ]

    perf_v1 = version_manager.evaluate_version_performance("v1.0", test_queries)
    perf_v2 = version_manager.evaluate_version_performance("v2.0", test_queries)

    print(f"版本1性能:")
    print(f"  准确率: {perf_v1['overall_metrics']['accuracy']*100:.1f}%")
    print(f"  平均响应时间: {perf_v1['overall_metrics']['avg_response_time']*1000:.1f}ms")

    print(f"\n版本2性能:")
    print(f"  准确率: {perf_v2['overall_metrics']['accuracy']*100:.1f}%")
    print(f"  平均响应时间: {perf_v2['overall_metrics']['avg_response_time']*1000:.1f}ms")

    print("\n" + "="*60 + "\n")

    # 功能4: 性能比较
    print("功能4: 性能比较与建议")
    perf_comparison = version_manager.compare_version_performance("v1.0", "v2.0", test_queries)

    print(f"性能比较结果:")
    comp = perf_comparison['performance_comparison']
    print(f"  准确率提升: {comp['accuracy']['improvement']*100:.1f}%")
    print(f"  响应时间变化: {comp['response_time']['improvement']*1000:.1f}ms")
    print(f"  建议: {perf_comparison['recommendation']}")

    print("\n" + "="*60 + "\n")

    # 功能5: 回归测试
    print("功能5: 回归测试")
    regression_v2 = version_manager.generate_regression_test("v2.0", test_queries)

    print(f"回归测试结果:")
    print(f"  测试通过率: {regression_v2['pass_rate']*100:.1f}%")
    print(f"  测试用例数量: {len(regression_v2['test_results'])}")

    print(f"\n详细测试结果:")
    for i, result in enumerate(regression_v2['test_results'], 1):
        status = "✓" if result['passed'] else "✗"
        print(f"  {i}. {result['query']} {status}")

if __name__ == "__main__":
    main() 
```
