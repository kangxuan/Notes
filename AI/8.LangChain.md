# LangChain

### 概念

`LangChain`是一个框架，支持python和TypeScript两种语言。`LangChain Python`提供了庞大的生态系统，包含了1000个多集成组件。涵盖了下面几个核心组件：

- Agents：智能体是将语言模型与工具结合而构建的系统，能够对任务进行推理，决定使用哪些工具，并迭代地朝着解决方案推荐。

- Models：

- Messages（prompt）

- Tools

- Memory

- Streaming

### 安装



# Agents

用户输入的内容给到Agent，Agent判断调用什么工具，结合工具+LLM返回给用户。

### ReAct模式

ReAct是一种智能体工作模式：Reason + Action

> 思考（Thought） → 行动（Action） → 观察（Observation）

- 模型首先输出其推理过程（思考）

- 然后选择并调用一个工具（行动）

- 接着接收工具返回的结果（观察）

- 并基于此更新计划，重复上述过程

这种模式能有效减少幻觉，并使决策过程可审计。智能体会形成假设（思考），通过工具验证（行动），再根据反馈调整策略（观察）。ReAct 循环将持续运行，直到满足停止条件——例如模型输出最终答案，或达到最大迭代次数限制。

### 举例：

##### 1、为公司取名

提供公司的产品，为公司取名。

```python
from langchain.agents import create_agent
from langchain_community.chat_models import ChatTongyi
import os

# 从环境变量获取 dashscope 的 API Key
api_key = os.environ.get('DASHSCOPE_API_KEY')
# 如果没有设置环境变量，可以在这里直接设置
if not api_key:
    # 注意：在实际生产环境中，建议通过环境变量设置API密钥
    # os.environ["DASHSCOPE_API_KEY"] = "your_api_key_here"
    raise ValueError("请设置环境变量'DASHSCOPE_API_KEY'以运行此程序。您可以在终端中使用以下命令设置：\nexport DASHSCOPE_API_KEY='your_api_key_here'")

# 创建模型
model = ChatTongyi(model="qwen-turbo")

# 创建系统提示词
system_prompt = "You are a helpful assistant that generates company names based on product descriptions."

# 创建代理
agent = create_agent(
    model=model,
    system_prompt=system_prompt
)

# 使用 invoke 方法传入包含产品信息的messages
result = agent.invoke({
    "messages": [{
        "role": "user", 
        "content": f"What is a good name for a company that makes {product}?"
    }]
})


while True:
    product = input("请输入要生成名称的产品（输入'退出'结束）: ")
    if product.lower() == '退出':
        break

    result = agent.invoke({
        "messages": [{
            "role": "user", 
            "content": f"What is a good name for a company that makes {product}?"
        }]
    })

    print("\n生成的公司名称:")
    print(result['messages'][-1].content)
```

运行结果：

```shell
$ python3 1-LLMChain_1.py
请输入要生成名称的产品（输入'退出'结束）: 牛奶

生成的公司名称:
A good name for a company that makes **milk** could be something that conveys freshness, purity, and trust. Here are a few suggestions:

1. **FreshMilk Co.**  
2. **PureDairy Farms**  
3. **GoldenMilk Industries**  
4. **Nature's Milk Co.**  
5. **DairyBloom**  
6. **MilkySource**  
7. **WhiteWave Dairy**  
8. **Cream & Co.**  
9. **LactoLife**  
10. **MilkCraft**

If you'd like the name to have a more traditional or cultural feel (e.g., Chinese-inspired), let me know, and I can suggest some as well!
```

# 使用Models

模型是智能体的推理引擎。他可以通过多种方式指定，支持静态和动态模型选择。

### 模型创建

##### 1、静态模型

**通过模型标识符字符串初始化：**

```python
from langchain.agents import create_agent

agent = create_agent("openai:gpt-5", tools=tools)
# 模型标识符格式为 provider:model（如 "openai:gpt-5"）
# 支持自动推断（如 "gpt-5" 会被推断为 "openai:gpt-5"）
```

**通过模型实例进行精细控制：**

```python
from langchain.agents import create_agent
from langchain_community.chat_models.tongyi import ChatTongyi

# 初始化通义千问模型
model = ChatTongyi(model_name="qwen-turbo")

# 使用初始化好的模型创建代理
agent = create_agent(model, tools=tools)
```

##### 2、动态模型

动态模型在运行时根据当前状态和上下文进行选择，适用于复杂的路由逻辑和成本优化。

你需要提供一个函数，该函数接收图状态（state）和运行时（runtime），并返回一个绑定了工具的 `BaseChatModel` 实例：

```python
from langchain.agents import create_agent, AgentState
from langgraph.runtime import Runtime
from langchain_community.chat_models.tongyi import ChatTongyi

def select_model(state: AgentState, runtime: Runtime) -> ChatTongyi:
    """根据对话复杂度选择模型。"""
    messages = state["messages"]
    message_count = len(messages)

    if message_count < 10:
        return ChatTongyi(model_name="qwen-turbo").bind_tools(tools)
    else:
        return ChatTongyi(model_name="qwen-max").bind_tools(tools)  # 更长对话使用更强模型

agent = create_agent(select_model, tools=tools)
```

### 模型案例

# 使用Tools

工具赋予智能体执行操作的能力。LangChain的智能体不仅支持简单的工具绑定，还支持：

- 单次提示触发多个工具的顺序调用

- 在适当时机并行调用工具

- 基于结果动态选择工具

- 工具重试逻辑与错误处理

- 跨工具调用的状态持久化

##### 1、Tool List

最简单的方式。传入工具列表会自动在内部创建一个 `ToolNode`：

```python
from langchain_core.tools import tool
from langchain.agents import create_agent

@tool
def search(query: str) -> str:
    """搜索信息。"""
    return f"Results for: {query}"

@tool
def calculate(expression: str) -> str:
    """执行计算。"""
    return str(eval(expression))

agent = create_agent(model, tools=[search, calculate])
```

##### 2、ToolNode

直接创建并配置 `ToolNode`，以自定义其行为（如错误处理）：

```python
tool_node = ToolNode(
    tools=[search, calculate],
    handle_tool_errors="请检查您的输入并重试。"
)
agent = create_agent(model, tools=tool_node)
```

### 举例：

##### 1、调用外部工具实现LLM功能增强

问：今天是几月几号?历史上的今天有哪些名人出生？

该问题单纯依赖LLM本身的能力有可能是没办法准确回答的，需要调用外部工具来实现功能增强。

```python
#!/usr/bin/env python
# coding: utf-8

import os
from langchain_community.chat_models import ChatTongyi
from langchain_community.agent_toolkits.load_tools import load_tools
from langchain_classic.agents import initialize_agent
from langchain_classic.agents import AgentType

# 从环境变量获取 dashscope 的 API Key
api_key = os.environ.get('DASHSCOPE_API_KEY')
# 如果没有设置环境变量，可以在这里直接设置
if not api_key:
    # 注意：在实际生产环境中，建议通过环境变量设置API密钥
    # os.environ["DASHSCOPE_API_KEY"] = "your_api_key_here"
    raise ValueError("请设置环境变量'DASHSCOPE_API_KEY'以运行此程序。您可以在终端中使用以下命令设置：\nexport DASHSCOPE_API_KEY='your_api_key_here'")

# 设置SerpAPI密钥（如果未在环境变量中设置）
if not os.environ.get('SERPAPI_API_KEY'):
    # 这里可以添加您的默认SerpAPI密钥，或者让用户在环境变量中设置
    pass

# 加载模型 - 使用最新的ChatTongyi代替Tongyi
llm = ChatTongyi(model="qwen-turbo")

# 加载 serpapi 工具
tools = load_tools(["serpapi"])

"""
agent：代理类型  
    zero-shot-react-description: 根据工具的描述和请求内容的来决定使用哪个工具（最常用）
    react-docstore: 使用 ReAct 框架和 docstore 交互, 使用Search 和Lookup 工具, 前者用来搜, 后者寻找term, 举例: Wipipedia 工具
    self-ask-with-search 此代理只使用一个工具: Intermediate Answer, 它会为问题寻找事实答案(指的非 gpt 生成的答案, 而是在网络中,文本中已存在的), 如 Google search API 工具
    conversational-react-description: 为会话设置而设计的代理, 它的prompt会被设计的具有会话性, 且还是会使用 ReAct 框架来决定使用来个工具, 并且将过往的会话交互存入内存
"""
# 工具加载后需要初始化，verbose=True 代表打印执行详情
agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True) 

# 运行 agent
result = agent.run("今天是几月几号?历史上的今天有哪些名人出生")
print("\n最终结果:", result)
```

运行结果：

```shell
python 2-LLMChain.py
/Users/kx/PycharmProjects/AI/CASE-LangChain/2-LLMChain.py:37: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the [LangGraph documentation](https://langchain-ai.github.io/langgraph/) as well as guides for [Migrating from AgentExecutor](https://python.langchain.com/docs/how_to/migrate_agent/) and LangGraph's [Pre-built ReAct agent](https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/).
  agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)


> Entering new AgentExecutor chain...
我需要先确定今天的日期，然后查找历史上的今天有哪些名人出生。
Action: Search
Action Input: 今天日期 历史上的今天名人出生
Observation: ['另可參見「維基百科:歷史上的今天」。 這是一份公曆日期列表，共一年三百六十六天（含閏年2月29日），用於索引特定日期的歷史、出生和死亡人物、節假日等信息。', '「今天生日的名人」是您了解當今名人生日的最佳地點，包括但不限於明星、藝人、歌手、演員、運動員、政治家等其他著名人物。 我們從維基百科整理資料，為您呈現關於他們 ...', '8月18日- 維基百科- 自由的百科全書| 歷史上的今天大事記| 節假日和習俗| 名人生日| 名人逝世| 名人的婚禮和離婚| 每日箴言| 每日食譜或健康飲食習慣 ...', '·民族解放斗争英雄苏克雷诞辰 · ·德国作曲家、钢琴家门德尔松诞辰 · ·美国在20世纪早期的重要画家诺曼·洛克威尔出生 · ·著名作家老舍诞辰 · ·农林生物学家、教育家乐天宇出生 ...', '“历史上的今天”是一款在线工具，旨在帮助用户快速查询任意日期在历史上发生的重大事件、重要人物的出生与逝世，以及一些特定日期的背景故事。 ... 答：多数“历史上的今天”工具 ...', '今天生日的名人. 宫部凉花 演员 1972年12月23日 99285. 详情 推荐理由:宫部凉花(みやべりょうか)，1972年12月23日出生于日本，其身高157cm，是日本女性演员。', '历史上的今天出生的明星 ; 1月前. 盘点今天生日的名人#伊布 #凯帕 #瓦尔德内尔 #陈立农 ; 4周前. 盘点今天（10月4号）的名人#郑伊健 #周鸿祎 #焦迈奇 #于洋 #张绍刚 ; 3月前.', '本页面是首页“历史上的今天”栏目本月模板的一个集合，其它月份模板的集合可以点击“按月份导航”的对应月份进入。如果需要编辑某日在首页“历史上的今天”展出的模板，点击该日期 ...', '本日出生的名人：. ·瑪麗．居禮：. 史上第一位女性諾貝爾奬得主，也是首位獲得物理與化學獎雙得主，最大的 ...', '历史上的今天-12月23日 ; 大事件. 208年. 周瑜火烧赤壁。 ; 出生名人. 968年. 宋真宗赵恒出生。 ; 逝世名人. 1834年. 英国经济学家马尔萨斯逝世。']
Thought:根据搜索结果，今天是12月23日。历史上的今天（12月23日）出生的名人包括：

- 玛丽·居礼（居里夫人）：史上第一位女性诺贝尔奖得主，也是首位获得物理与化学奖双得主。
- 宋真宗赵恒：968年出生。
- 宫部凉花：日本女演员，1972年12月23日出生。

Final Answer: 今天是12月23日。历史上的今天（12月23日）出生的名人包括玛丽·居礼、宋真宗赵恒和日本女演员宫部凉花。

> Finished chain.

最终结果: {'input': '今天是几月几号?历史上的今天有哪些名人出生', 'output': '今天是12月23日。历史上的今天（12月23日）出生的名人包括玛丽·居礼、宋真宗赵恒和日本女演员宫部凉花。'}
```

##### 2、调用自定义的tool来增强功能

可以自定义tool，让LLM来根据用户提问的理解来调用自定义的tool，来更好的回答用户提问。

```python
# 设置通义千问API密钥
import os
import json
from langchain_classic.tools import Tool
from langchain_community.chat_models.tongyi import ChatTongyi
import langchain_classic.hub as hub
from langchain_classic.agents import create_react_agent, AgentExecutor
from langchain_classic.memory import ConversationBufferMemory
from typing import List, Union, Dict, Any



# 从环境变量获取 dashscope 的 API Key
api_key = os.environ.get('DASHSCOPE_API_KEY')
# 如果没有设置环境变量，可以在这里直接设置
if not api_key:
    # 注意：在实际生产环境中，建议通过环境变量设置API密钥
    # os.environ["DASHSCOPE_API_KEY"] = "your_api_key_here"
    raise ValueError("请设置环境变量'DASHSCOPE_API_KEY'以运行此程序。您可以在终端中使用以下命令设置：\nexport DASHSCOPE_API_KEY='your_api_key_here'")

# 自定义工具1：文本分析工具
class TextAnalysisTool:
    """文本分析工具，用于分析文本内容"""

    def __init__(self) -> None:
        self.name = "文本分析"
        self.description = "分析文本内容，提取字数、字符数和情感倾向"

    def run(self, text: str) -> str:
        """分析文本内容

        参数:
            text: 要分析的文本
        返回:
            分析结果
        """
        word_count = len(text.split())
        char_count = len(text)

        # 简单的情感分析（示例）
        positive_words = ["好", "优秀", "喜欢", "快乐", "成功", "美好"]
        negative_words = ["差", "糟糕", "讨厌", "悲伤", "失败", "痛苦"]

        # 统计情感词出现的次数
        positive_count = sum(1 for word in positive_words if word in text)
        negative_count = sum(1 for word in negative_words if word in text)

        sentiment = "正面" if positive_count > negative_count else "负面" if negative_count > positive_count else "中性"

        return f"文本分析结果:\n- 字数: {word_count}\n- 字符数: {char_count}\n- 情感倾向: {sentiment}"

# 自定义工具2：数据转换工具
class DataConversionTool:
    """数据转换工具，用于将文本转换为不同格式"""

    def __init__(self) -> None:
        self.name = "数据转换"
        self.description = "将文本转换为不同格式，如JSON、CSV等。需要JSON格式输入，包含input_data(要转换的数据)、input_format(输入格式)、output_format(输出格式)字段"

    def run(self, input_str: str) -> str:
        """将文本转换为指定格式

        参数:
            input_str: JSON格式的输入字符串，包含input_data、input_format和output_format
        返回:
            转换后的文本数据
        """
        try:
            # 解析JSON输入
            input_data = json.loads(input_str)
            data_content = input_data.get("input_data", "")
            input_format = input_data.get("input_format", "").lower()
            output_format = input_data.get("output_format", "").lower()

            if not data_content or not input_format or not output_format:
                return "输入参数不完整，请提供input_data、input_format和output_format"

            # 简单的示例：将JSON转换为CSV
            if input_format == "json" and output_format == "csv":
                # json格式转换为csv格式
                data = json.loads(data_content)
                if isinstance(data, list):
                    if not data:
                        return "空数据"

                    # 获取所有可能的列
                    headers = set()
                    for item in data:
                        headers.update(item.keys())
                    headers = list(headers)

                    # 创建csv
                    csv = ",".join(headers) + "\n"
                    for item in data:
                        row = [str(item.get(header, "")) for header in headers]
                        csv += ",".join(row) + "\n"

                    return csv
                else:
                    return "输入数据必须是JSON数组"
            elif input_format == 'csv' and output_format == 'json':
                # csv格式转换为json格式
                lines = data_content.strip().split("\n")
                headers = lines[0].split(",")
                json_data = []
                for line in lines[1:]:
                    values = line.split(",")
                    item = dict(zip(headers, values))
                    json_data.append(item)
                return json.dumps(json_data, ensure_ascii=False, indent=2)
            else:
                return f"不支持从{input_format}转换到{output_format}"
        except json.JSONDecodeError as e:
            return f"JSON解析错误: {e}"
        except Exception as e:
            return f"转换数据时出错: {e}"

# 自定义工具3：文本处理工具
class TextProcessingTool:
    """文本处理工具，用于处理文本内容"""

    def __init__(self) -> None:
        self.name = "文本处理"
        self.description = "处理文本内容，如查找、替换、统计等。需要JSON格式输入，包含operation(操作类型)、content(要处理的文本)字段，其他参数根据操作类型而定"

    def run(self, input_str: str) -> str:
        """处理文本内容

        参数:
            input_str: JSON格式的输入字符串，包含operation、content和其他参数
        返回:
            处理后的文本
        """
        try:
            # 解析JSON输入
            input_data = json.loads(input_str)
            operation = input_data.get("operation", "").lower()
            content = input_data.get("content", "")

            if operation == "count_lines" or operation == "统计行数":
                # 统计文本行数
                return f"文本共{len(content.splitlines())}行"
            elif operation == "find_text" or operation == "查找文本":
                # 查找文本有几处匹配
                search_text = input_data.get("search_text", "")
                if not search_text:
                    return "请提供要查找的文本"

                lines = content.splitlines()
                matches = []
                for i, line in enumerate(lines, 1):
                    if search_text in line:
                        matches.append(f"第{i}行: {line}")

                if matches:
                    return f"找到 {len(matches)} 处匹配:\n" + "\n".join(matches)
                else:
                    return f"文本中不包含'{search_text}'"
            elif operation == "replace_text" or operation == "替换文本":
                # 替换文本
                old_text = input_data.get("old_text", "")
                new_text = input_data.get("new_text", "")
                if not old_text:
                    return "请提供要替换的文本"

                new_content = content.replace(old_text, new_text)
                count = content.count(old_text)

                return f"替换完成，共替换 {count} 处。\n新内容:\n{new_content}"
            else:
                return f"不支持操作{operation}"
        except json.JSONDecodeError:
            # 如果不是JSON格式，尝试直接解析为统计行数的操作
            if "统计行数" in input_str:
                # 提取内容部分
                import re
                content_match = re.search(r'"content":\s*"(.*?)"', input_str)
                if content_match:
                    content = content_match.group(1)
                    return f"文本共{len(content.splitlines())}行"
            return f"输入格式错误，请提供JSON格式的输入，例如：{{\"operation\": \"count_lines\", \"content\": \"要处理的文本\"}}"

# 创建LangChain工具链
def create_tool_chain():
    """创建一个包含所有自定义工具的LangChain工具链"""
    text_analysis = TextAnalysisTool()
    data_conversion = DataConversionTool()
    text_processing = TextProcessingTool()
    tools = [
        Tool(
            name=text_analysis.name,
            func=text_analysis.run,
            description=text_analysis.description
        ),
        Tool(
            name=data_conversion.name,
            func=data_conversion.run,
            description=data_conversion.description
        ),
        Tool(
            name=text_processing.name,
            func=text_processing.run,
            description=text_processing.description
        ),
    ]

    # 创建ReAct代理，使用LangChain内置的ReAct提示词模板
    prompt = hub.pull("hwchase17/react")

    model = ChatTongyi(model_name="qwen-turbo")

    agent = create_react_agent(
        llm=model,
        tools=tools,
        prompt=prompt
    )

    # 创建Agent执行器
    agent_executor = AgentExecutor.from_agent_and_tools(
        agent=agent,
        tools=tools,
        memory=ConversationBufferMemory(memory_key="chat_history"),
        verbose=True,
        handle_parsing_errors=False  # 关闭自动重试, True会严格检查重试
    )

    return agent_executor

# 示例：使用工具链处理任务
def process_task(task_description):
    """
    使用工具链处理任务

    参数:
        task_description: 任务描述
    返回:
        处理结果
    """
    try:
        agent_executor = create_tool_chain()
        response = agent_executor.invoke({"input": task_description})
        return response["output"]  # 从返回的字典中提取输出
    except Exception as e:
        return f"处理任务时出错: {str(e)}"

if __name__ == "__main__":
    # 示例1: 文本分析与处理
    task1 = "分析以下文本的情感倾向，并统计其中的行数：'这个产品非常好用，我很喜欢它的设计，使用体验非常棒！\n价格也很合理，推荐大家购买。\n客服态度也很好，解答问题很及时。'"
    print("任务1:", task1)
    print("结果:", process_task(task1))

    # 示例2: 数据格式转换
    task2 = "将以下CSV数据转换为JSON格式：'name,age,comment\n张三,25,这个产品很好\n李四,30,服务态度差\n王五,28,性价比高'"
    print("\n任务2:", task2)
    print("结果:", process_task(task2))
```

运行结果：

```shell
python 1_simple_toolchain.py 
任务1: 分析以下文本的情感倾向，并统计其中的行数：'这个产品非常好用，我很喜欢它的设计，使用体验非常棒！
价格也很合理，推荐大家购买。
客服态度也很好，解答问题很及时。'
/Users/kx/PycharmProjects/AI/CASE-LangChain-工具链组合/1_simple_toolchain.py:222: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/
  memory=ConversationBufferMemory(memory_key="chat_history"),


> Entering new AgentExecutor chain...
我需要使用文本分析工具来分析情感倾向并统计行数。
Action: 文本分析
Action Input: '这个产品非常好用，我很喜欢它的设计，使用体验非常棒！\n价格也很合理，推荐大家购买。\n客服态度也很好，解答问题很及时。'文本分析结果:
- 字数: 1
- 字符数: 62
- 情感倾向: 正面文本分析结果中没有明确给出行数信息，需要进一步处理。我应该使用文本处理工具来统计行数。
Action: 文本处理
Action Input: {"operation": "统计行数", "content": "这个产品非常好用，我很喜欢它的设计，使用体验非常棒！\n价格也很合理，推荐大家购买。\n客服态度也很好，解答问题很及时。"}文本共3行现在我已获得文本的情感倾向和行数信息。
Final Answer: 该文本的情感倾向为正面，共有3行。

> Finished chain.
结果: 该文本的情感倾向为正面，共有3行。

任务2: 将以下CSV数据转换为JSON格式：'name,age,comment
张三,25,这个产品很好
李四,30,服务态度差
王五,28,性价比高'


> Entering new AgentExecutor chain...
需要使用数据转换工具将CSV数据转换为JSON格式。
Action: 数据转换
Action Input: {"input_data":"name,age,comment\n张三,25,这个产品很好\n李四,30,服务态度差\n王五,28,性价比高","input_format":"csv","output_format":"json"}[
  {
    "name": "张三",
    "age": "25",
    "comment": "这个产品很好"
  },
  {
    "name": "李四",
    "age": "30",
    "comment": "服务态度差"
  },
  {
    "name": "王五",
    "age": "28",
    "comment": "性价比高"
  }
]数据已成功转换为JSON格式。  
Final Answer: [
  {
    "name": "张三",
    "age": "25",
    "comment": "这个产品很好"
  },
  {
    "name": "李四",
    "age": "30",
    "comment": "服务态度差"
  },
  {
    "name": "王五",
    "age": "28",
    "comment": "性价比高"
  }
]

> Finished chain.
结果: [
  {
    "name": "张三",
    "age": "25",
    "comment": "这个产品很好"
  },
  {
    "name": "李四",
    "age": "30",
    "comment": "服务态度差"
  },
  {
    "name": "王五",
    "age": "28",
    "comment": "性价比高"
  }
]
```

##### 3、自定义任务链

已知任务调用的先后顺序，可以自定义任务调用的先后顺序。

```python
from langchain_core.prompts import ChatPromptTemplate
from langchain_community.chat_models.tongyi import ChatTongyi
from langchain_core.output_parsers import StrOutputParser
import dashscope
import os

# 从环境变量获取 dashscope 的 API Key
api_key = os.environ.get('DASHSCOPE_API_KEY')
# 如果没有设置环境变量，可以在这里直接设置
if not api_key:
    # 注意：在实际生产环境中，建议通过环境变量设置API密钥
    # os.environ["DASHSCOPE_API_KEY"] = "your_api_key_here"
    raise ValueError("""请设置环境变量'DASHSCOPE_API_KEY'以运行此程序。您可以在终端中使用以下命令设置：
export DASHSCOPE_API_KEY='your_api_key_here'""")

# stream=True 让LLM支持流式输出
llm = ChatTongyi(model_name="qwen-turbo", streaming=True)

# 定义三个子任务：翻译->处理->回译
translate_to_en = ChatPromptTemplate.from_template("Translate this to English: {input}") | llm | StrOutputParser()
process_text = ChatPromptTemplate.from_template("Analyze this text: {text}") | llm | StrOutputParser()
translate_to_cn = ChatPromptTemplate.from_template("Translate this to Chinese: {output}") | llm | StrOutputParser()

# 组合成多任务链
workflow = {"text": translate_to_en} | process_text | translate_to_cn
#workflow.invoke({"input": "北京有哪些好吃的地方，简略回答不超过200字"})

# 使用stream方法，边生成边打印
for chunk in workflow.stream({"input": "北京有哪些好吃的地方，简略回答不超过200字"}):
    print(chunk, end="", flush=True)
print()  # 换行
```

运行结果：

```shell
$ python 3_lcel.py 
北京提供丰富的餐饮选择，从传统的北京烤鸭到现代融合菜系。要品尝地道的地方风味，可以去**全聚德**或**东来顺**，分别品尝北京烤鸭和火锅。**王府井大街**是品尝煎饼和烤串等街头美食的好地方。如果想享受高档餐饮，**元元**和**京华酒店餐厅**提供优雅的中式和国际菜肴。像**林合西**和**胡同**这样的食品市场则提供休闲而美味的餐食。别忘了去**天桥**品尝传统小吃。每个区域都有其独特的魅力，使北京成为美食爱好者的天堂。
```

# Prompt
